
@online{2014,
  title = {Morgan {{Stanley}}: {{ETF Tracking Error Dropping}}},
  shorttitle = {Morgan {{Stanley}}},
  date = {2014-12-20T11:26:20-05:00},
  url = {https://www.etf.com/sections/features/11269-morgan-stanley-etf-tracking-error-dropping-morgan-stanley-etf-tracking-error-dropping-.html},
  urldate = {2020-05-07},
  abstract = {ETF investors are reaping the benefits of an industry that is cutting down fund tracking error.},
  langid = {english},
  organization = {{ETF.com}},
  file = {/Users/agwd/Zotero/storage/LLH7D2XR/11269-morgan-stanley-etf-tracking-error-dropping-morgan-stanley-etf-tracking-error-dropping-.html}
}

@book{2015,
  title = {Access to and Preservation of Scientific Information in {{Europe}}: Report on the Implementation of {{Commission Recommendation C}}(2012) 4890 Final.},
  shorttitle = {Access to and Preservation of Scientific Information in {{Europe}}},
  date = {2015},
  publisher = {{Publications Office}},
  location = {{LU}},
  url = {https://data.europa.eu/doi/10.2777/975917},
  urldate = {2020-09-11},
  langid = {english}
}

@book{2015a,
  title = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}: {{Report}} on the {{Implementation}} of {{Commission Recommendation C}}(2012) 4890 {{Final}}.},
  shorttitle = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}},
  date = {2015},
  publisher = {{Publications Office}},
  location = {{LU}},
  langid = {english},
  keywords = {done}
}

@book{2015b,
  title = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}: {{Report}} on the {{Implementation}} of {{Commission Recommendation C}}(2012) 4890 {{Final}}.},
  shorttitle = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}},
  date = {2015},
  publisher = {{Publications Office}},
  location = {{LU}},
  langid = {english},
  keywords = {done}
}

@online{2019,
  title = {Tracking {{Error Formula}} | {{Step}} by {{Step Calculation}} (with {{Examples}})},
  date = {2019-03-21T09:21:53+00:00},
  url = {https://www.wallstreetmojo.com/tracking-error-formula/},
  urldate = {2020-05-07},
  abstract = {Guide to Tracking Error~Formula. Here we discuss how to calculate tracking error for the portfolio along with examples and downloadable excel template.},
  langid = {american},
  organization = {{WallStreetMojo}},
  file = {/Users/agwd/Zotero/storage/YBWR275X/tracking-error-formula.html}
}

@book{AccessPreservationScientific2015,
  title = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}: {{Report}} on the {{Implementation}} of {{Commission Recommendation C}}(2012) 4890 {{Final}}.},
  shorttitle = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}},
  date = {2015},
  publisher = {{Publications Office}},
  location = {{LU}},
  langid = {english},
  keywords = {done}
}

@book{AccessPreservationScientific2015a,
  title = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}: {{Report}} on the {{Implementation}} of {{Commission Recommendation C}}(2012) 4890 {{Final}}.},
  shorttitle = {Access to and {{Preservation}} of {{Scientific Information}} in {{Europe}}},
  date = {2015},
  publisher = {{Publications Office}},
  location = {{LU}},
  langid = {english},
  keywords = {done}
}

@article{adair2000,
  title = {House Prices and Accessibility: The Testing of {{Relationships}} within the {{Belfast}} Urban Area},
  author = {Adair, A and McGreal, S and Smyth, A and Cooper, J and Ryley, T},
  date = {2000},
  journaltitle = {Housing studies},
  volume = {15},
  pages = {699--716},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@online{adam2018,
  title = {My Favourite {{R}} Package for: Summarising Data},
  shorttitle = {My Favourite {{R}} Package For},
  author = {{Adam}},
  date = {2018-01-02T08:49:22+00:00},
  url = {https://dabblingwithdata.wordpress.com/2018/01/02/my-favourite-r-package-for-summarising-data/},
  urldate = {2020-09-02},
  abstract = {Hot on the heels of delving into the world of R frequency table tools, it’s now time to expand the scope and think about data summary functions in general. One of the first steps analysts sho…},
  langid = {english},
  organization = {{Dabbling with Data}},
  file = {/Users/agwd/Zotero/storage/2UNFTJQZ/my-favourite-r-package-for-summarising-data.html}
}

@online{adam2018a,
  title = {My Favourite {{R}} Package for: Summarising Data},
  shorttitle = {My Favourite {{R}} Package For},
  author = {{Adam}},
  date = {2018-01-02T08:49:22+00:00},
  url = {https://dabblingwithdata.wordpress.com/2018/01/02/my-favourite-r-package-for-summarising-data/},
  urldate = {2020-09-01},
  abstract = {Hot on the heels of delving into the world of R frequency table tools, it’s now time to expand the scope and think about data summary functions in general. One of the first steps analysts sho…},
  langid = {english},
  organization = {{Dabbling with Data}},
  file = {/Users/agwd/Zotero/storage/36MJQ97Q/my-favourite-r-package-for-summarising-data.html}
}

@article{ahlfeldt2011,
  title = {If Alonso Was Right: Modelling Accessibility and Explaining the Residential Land Gradient},
  author = {Ahlfeldt, G},
  date = {2011},
  journaltitle = {Journal of Regional Science},
  volume = {51},
  number = {2},
  date-modified = {2012-02-28 12:24:08 +0000},
  unidentified = {3138-338},
  keywords = {ocp022019_REGION_template}
}

@article{alexanas1998,
  title = {Urban Spatial Structure},
  author = {Alex Anas, Richard Arnott and Small, Kenneth A.},
  date = {1998-09},
  journaltitle = {Journal of Economic Literature},
  volume = {36},
  number = {3},
  pages = {1416--1464},
  date-added = {2015-10-16 12:40:03 +0000},
  date-modified = {2015-10-16 12:42:06 +0000}
}

@book{allaire2020,
  title = {Rmarkdown: {{Dynamic Documents}} for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  keywords = {done}
}

@book{allaire2020a,
  title = {Rmarkdown: {{Dynamic Documents}} for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  keywords = {done}
}

@book{allaire2020b,
  title = {Rmarkdown: {{Dynamic}} Documents for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  url = {https://github.com/rstudio/rmarkdown}
}

@book{allaireRmarkdownDynamicDocuments2020,
  title = {Rmarkdown: {{Dynamic Documents}} for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  keywords = {done}
}

@book{allaireRmarkdownDynamicDocuments2020a,
  title = {Rmarkdown: {{Dynamic Documents}} for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  keywords = {done}
}

@article{almas2012,
  title = {Norske børshandlede fond : en kvantitativ analyse av fondenes egenskaper},
  shorttitle = {Norske børshandlede fond},
  author = {Almås, Pål Jonas Brandåstrø and Andersen, Kristian Peder Mørtvedt},
  date = {2012},
  url = {https://openaccess.nhh.no/nhh-xmlui/handle/11250/169733},
  urldate = {2020-05-07},
  abstract = {Denne masterutredningen handler om børshandlede fond tilbudt av DNB og Handelsbanken. Ved hjelp av regresjonsanalyser og t-tester undersøker vi hvor godt fondene følger deres referanseindeks, som er OBX-indeksen. Vi tester også for hvilken fondstilbyder som følger referanseindeksen best. Videre ser vi på hvordan fondsmekanismene i girede børshandlede fond endres ved en «kjøp-og-hold»-strategi, og benytter Monte Carlo-simulering, en volatilitetsmodell og en rentemodell for å undersøke dette.  Våre analyser tyder på at alle fondene historisk har gitt en lavere daglig avkastningsmultippel enn det som er kommunisert i fondsprospektene. Ved sammenligning av fondstilbydere kommer vi frem til at DNB sitt indeksfond og Handelsbankens Bear-fond kommer nærmest lovet avkastningsmultippel i deres kategori. Bull-fondene fra de to tilbyderne klarer vi ikke å skille. Ved undersøkelse av fondsmekanismer finner vi ut at ved høyere volatilitet, og lengre tidshorisont, vil fondsverdiene bli redusert over tid. Dette viser også en empirisk analyse vi gjennomførte på datasettet vårt.},
  langid = {norsk},
  annotation = {Accepted: 2012-08-21T10:23:49Z},
  file = {/Users/agwd/Zotero/storage/WEBADNGJ/Almås og Andersen - 2012 - Norske børshandlede fond  en kvantitativ analyse .pdf;/Users/agwd/Zotero/storage/EJX2SUIL/169733.html}
}

@book{AmericanEconomicAssociation,
  title = {American {{Economic Association}}}
}

@book{AmericanEconomicAssociationa,
  title = {American {{Economic Association}}}
}

@article{anas1998,
  title = {Urban Spatial Structure},
  author = {Anas, A and Arnott, RA and Small, K},
  date = {1998},
  journaltitle = {Journal of Economic Literature},
  volume = {36},
  pages = {1426--1464},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{anselin1988,
  title = {Spatial Econometrics: Methods and Models},
  author = {Anselin, L},
  date = {1988},
  publisher = {{Kluwer}},
  location = {{London}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{anselin2002,
  title = {Under the Hood. {{Issues}} in the Specification and Interpretation of Spatial Regression Models},
  author = {Anselin, L},
  date = {2002},
  journaltitle = {Agricultural Economics},
  volume = {27},
  pages = {247--267},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@incollection{anselin2009,
  title = {Spatial Hedonic Models},
  booktitle = {Ch. 26 in Palgrave Handbook of Econometrics Vol 2},
  author = {Anselin, L and Lozano-Gracia, N},
  editor = {TC, Mills and (eds), K Patterson},
  date = {2009},
  publisher = {{Palgrave Macmillan}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@manual{aust2019,
  type = {manual},
  title = {Citr: '{{RStudio}}' Add-in to Insert Markdown Citations},
  author = {Aust, Frederik},
  date = {2019},
  url = {https://CRAN.R-project.org/package=citr}
}

@article{ball1977,
  title = {Accessibility and Supply Constraints in the Urban Housing Market},
  author = {Ball, MJ and Kirwan, RM},
  date = {1977},
  journaltitle = {Urban Studies},
  volume = {14},
  pages = {11--32},
  date-modified = {2012-02-28 12:44:43 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{bao2004,
  title = {On the Use of Spline Smoothing in Estimating Hedonic Housing Price Models: Empirical Evidence Using {{Hong Kong}} Data},
  author = {Bao, HXH and Wan, ATK},
  date = {2004},
  journaltitle = {Real Estate Economics},
  volume = {32},
  pages = {487--507},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{barnes2010,
  title = {Publish {{Your Computer Code}}: {{It Is Good Enough}}},
  shorttitle = {Publish {{Your Computer Code}}},
  author = {Barnes, Nick},
  date = {2010-10},
  journaltitle = {Nature},
  volume = {467},
  number = {7317},
  pages = {753--753},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/467753a},
  langid = {english}
}

@article{barnes2010a,
  title = {Publish {{Your Computer Code}}: {{It Is Good Enough}}},
  shorttitle = {Publish {{Your Computer Code}}},
  author = {Barnes, Nick},
  date = {2010-10},
  journaltitle = {Nature},
  volume = {467},
  number = {7317},
  pages = {753--753},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/467753a},
  langid = {english}
}

@article{barnes2010b,
  title = {Publish Your Computer Code: It Is Good Enough},
  shorttitle = {Publish Your Computer Code},
  author = {Barnes, Nick},
  date = {2010-10},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {467},
  number = {7317},
  pages = {753--753},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/467753a},
  url = {http://www.nature.com/articles/467753a},
  urldate = {2020-09-11},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/W9T2UN9W/Barnes - 2010 - Publish your computer code it is good enough.pdf}
}

@article{barnesPublishYourComputer2010,
  title = {Publish {{Your Computer Code}}: {{It Is Good Enough}}},
  shorttitle = {Publish {{Your Computer Code}}},
  author = {Barnes, Nick},
  date = {2010-10},
  journaltitle = {Nature},
  volume = {467},
  number = {7317},
  pages = {753--753},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/467753a},
  langid = {english}
}

@article{barnesPublishYourComputer2010a,
  title = {Publish {{Your Computer Code}}: {{It Is Good Enough}}},
  shorttitle = {Publish {{Your Computer Code}}},
  author = {Barnes, Nick},
  date = {2010-10},
  journaltitle = {Nature},
  volume = {467},
  number = {7317},
  pages = {753--753},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/467753a},
  langid = {english}
}

@article{baum2007,
  title = {Enhanced Routines for Instrumental Variables/Generalized Method of Moments Estimation and Testing},
  author = {Baum, C. F. and Schaffer, M. E. and Stillman, S.},
  date = {2007},
  journaltitle = {Stata Journal},
  volume = {7},
  number = {4},
  pages = {465--506},
  url = {http://www.stata-journal.com/article.html?article=st0030_3},
  keywords = {CUE,Cumby-Huizinga test,endogeneity,Frisch-Waugh-Lovell theorem,GMM,HAC standard errors,heteroskedasticity,instrumental variables,ivactest,ivendog,ivhettest,ivreg2,ivreset,LIML,overid,overidentifying restrictions,ranktest,RESET,serial correlation,weak instruments}
}

@article{bechhofer2013,
  title = {Why {{Linked Data Is Not Enough}} for {{Scientists}}},
  author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
  date = {2013-02},
  journaltitle = {Future Generation Computer Systems},
  volume = {29},
  number = {2},
  pages = {599--611},
  issn = {0167739X},
  doi = {10.1016/j.future.2011.08.004},
  langid = {english},
  keywords = {done}
}

@article{bechhofer2013a,
  title = {Why {{Linked Data Is Not Enough}} for {{Scientists}}},
  author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
  date = {2013-02},
  journaltitle = {Future Generation Computer Systems},
  volume = {29},
  number = {2},
  pages = {599--611},
  issn = {0167739X},
  doi = {10.1016/j.future.2011.08.004},
  langid = {english},
  keywords = {done}
}

@article{bechhofer2013b,
  title = {Why Linked Data Is Not Enough for Scientists},
  author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
  date = {2013-02},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {29},
  number = {2},
  pages = {599--611},
  issn = {0167739X},
  doi = {10.1016/j.future.2011.08.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X11001439},
  urldate = {2020-09-11},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/K8CPQ95S/Bechhofer et al. - 2013 - Why linked data is not enough for scientists.pdf}
}

@article{bechhoferWhyLinkedData2013,
  title = {Why {{Linked Data Is Not Enough}} for {{Scientists}}},
  author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
  date = {2013-02},
  journaltitle = {Future Generation Computer Systems},
  volume = {29},
  number = {2},
  pages = {599--611},
  issn = {0167739X},
  doi = {10.1016/j.future.2011.08.004},
  langid = {english},
  keywords = {done}
}

@article{bechhoferWhyLinkedData2013a,
  title = {Why {{Linked Data Is Not Enough}} for {{Scientists}}},
  author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
  date = {2013-02},
  journaltitle = {Future Generation Computer Systems},
  volume = {29},
  number = {2},
  pages = {599--611},
  issn = {0167739X},
  doi = {10.1016/j.future.2011.08.004},
  langid = {english},
  keywords = {done}
}

@article{bianco2019,
  title = {Understanding Energy Consumption and Carbon Emissions in {{Europe}}: {{A}} Focus on Inequality Issues},
  shorttitle = {Understanding Energy Consumption and Carbon Emissions in {{Europe}}},
  author = {Bianco, Vincenzo and Cascetta, Furio and Marino, Alfonso and Nardini, Sergio},
  date = {2019-03-01},
  journaltitle = {Energy},
  shortjournal = {Energy},
  volume = {170},
  pages = {120--130},
  issn = {0360-5442},
  doi = {10.1016/j.energy.2018.12.120},
  abstract = {The present research proposes an analysis on the inequality of the consumption of electricity, different typologies of primary energy, namely natural gas, coal and oil, and carbon emissions in the period 2008 -2016 within European Union. A decomposition in within and between country groups on the basis of their GDP per capita is also developed, in order to identify the main contributions to the inequality. Furthermore, carbon emissions are also decomposed according to the Kaya identity with the aim to assess which are the main sources of inequality. The analysis shows that the principal source of inequality is represented by the differences in GDP, especially for the energy consumption; whereas carbon emissions evidence a stable level of inequality during the period of analysis. (C) 2018 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {Carbon emissions,co2 emissions,countries,decomposition,efficiency,electricity consumption,Energy consumption,eu,growth,Inequality,intensities,Kaya   identity,policy,Theil index},
  annotation = {WOS:000460845700013}
}

@book{bie1980,
  title = {Forslag Til Utvekslingsformat for Digitale Geodata ({{SOSI}}-Formatet, Versjon 1.0)},
  author = {Bie, Stein W. 1943- and Stormark, Einar},
  date = {1980},
  publisher = {{Norsk regnesentral}},
  location = {{Oslo}},
  isbn = {82-539-0151-8},
  pagetotal = {27 bl. fig., tab. 4°},
  keywords = {Databasert kartfremstilling,Geodatasystemer}
}

@book{bivand,
  title = {Spatial {{Data Science}}},
  author = {Bivand, Roger, Edzer Pebesma},
  url = {https://keen-swartz-3146c4.netlify.app/index.html},
  urldate = {2021-05-12},
  abstract = {description\_xx},
  file = {/Users/agwd/Zotero/storage/PTPH5UHT/index.html}
}

@article{bivand1984,
  title = {Regression Modelling with Spatial Dependence: {{An}} Application of Some Class Selection and Estimation Methods},
  author = {Bivand, R},
  date = {1984},
  journaltitle = {Geographical Analysis},
  volume = {16},
  number = {1},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{bivand2008,
  title = {Applied Spatial Data Analysis with {{R}}},
  author = {Bivand, RS and Pebesma, EJ and Gόmez-Rubio, V},
  date = {2008},
  publisher = {{Springer}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{bivand2011,
  title = {After '{{Raising}} the {{Bar}}': {{Applied Maximum Likelihood Estimation}} of {{Families}} of {{Models}} in {{Spatial Econometrics}}},
  shorttitle = {After '{{Raising}} the {{Bar}}'},
  author = {Bivand, Roger},
  date = {2011},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.1972278},
  url = {http://www.ssrn.com/abstract=1972278},
  urldate = {2021-06-20},
  abstract = {Elhorst (2010) shows how the recent publication of LeSage and Pace (2009) in his expression “raises the bar” for our fitting of spatial econometrics models. By extending the family of models that deserve attention, Elhorst reveals the need to explore how they might be fitted, and discusses some alternatives. This paper attempts to take up this challenge with respect to implementation in the R spdep package for the maximum likelihood case, using a smaller data set to see whether earlier conclusions would be changed when newer techniques are used, and two larger data sets to examine model fitting issues.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/MG93ISGA/Bivand - 2011 - After 'Raising the Bar' Applied Maximum Likelihoo.pdf}
}

@article{bivand2011a,
  title = {After '{{Raising}} the {{Bar}}': {{Applied Maximum Likelihood Estimation}} of {{Families}} of {{Models}} in {{Spatial Econometrics}}},
  shorttitle = {After '{{Raising}} the {{Bar}}'},
  author = {Bivand, Roger},
  date = {2011},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.1972278},
  url = {http://www.ssrn.com/abstract=1972278},
  urldate = {2021-06-20},
  abstract = {Elhorst (2010) shows how the recent publication of LeSage and Pace (2009) in his expression “raises the bar” for our fitting of spatial econometrics models. By extending the family of models that deserve attention, Elhorst reveals the need to explore how they might be fitted, and discusses some alternatives. This paper attempts to take up this challenge with respect to implementation in the R spdep package for the maximum likelihood case, using a smaller data set to see whether earlier conclusions would be changed when newer techniques are used, and two larger data sets to examine model fitting issues.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/TFTPY7D3/Bivand - 2011 - After 'Raising the Bar' Applied Maximum Likelihoo.pdf}
}

@software{bivand2017,
  title = {Spgwr: {{Geographically Weighted Regression}}},
  shorttitle = {Spgwr},
  author = {Bivand, Roger and Yu, Danlin and Nakaya, Tomoki and Garcia-Lopez, Miquel-Angel},
  date = {2017-10-29},
  url = {https://CRAN.R-project.org/package=spgwr},
  urldate = {2019-04-10},
  abstract = {Functions for computing geographically weighted regressions are provided, based on work by Chris Brunsdon, Martin Charlton and Stewart Fotheringham.},
  version = {0.6-32},
  keywords = {Spatial}
}

@article{bivand2021,
  title = {A {{Review}} of {{Software}} for {{Spatial Econometrics}} in {{R}}},
  author = {Bivand, Roger and Millo, Giovanni and Piras, Gianfranco},
  date = {2021-01},
  journaltitle = {Mathematics},
  volume = {9},
  number = {11},
  pages = {1276},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/math9111276},
  url = {https://www.mdpi.com/2227-7390/9/11/1276},
  urldate = {2021-06-25},
  abstract = {The software for spatial econometrics available in the R system for statistical computing is reviewed. The methods are illustrated in a historical perspective, highlighting the main lines of development and employing historically relevant datasets in the examples. Estimators and tests for spatial cross-sectional and panel models based either on maximum likelihood or on generalized moments methods are presented. The paper is concluded reviewing some current active lines of research in spatial econometric software methods.},
  issue = {11},
  langid = {english},
  keywords = {R,review,software,spatial econometrics},
  file = {/Users/agwd/Zotero/storage/DXIZYNAE/Bivand et al. - 2021 - A Review of Software for Spatial Econometrics in R.pdf;/Users/agwd/Zotero/storage/2NSNMHKK/1276.html}
}

@book{bodie2014,
  title = {Investments},
  author = {Bodie, Zvi},
  date = {2014},
  edition = {10th global ed.},
  publisher = {{McGraw-Hill Education}},
  location = {{Berkshire}},
  editora = {Marcus, Alan J. and Kane, Alex},
  editoratype = {collaborator},
  isbn = {978-0-07-716114-9},
  langid = {english},
  keywords = {Economics,Finance,finansiering,finansmarked,finansøkonomi,investering,Investering,Investeringer,Investeringsformer,Investment,ledelse,Portefølje,porteføljer,portfolio,risikoanalyse,styring,Varer : Investering : Bank- og pengevesen,Verdipapirer : Investering : Bank- og pengevesen}
}

@report{bollen2015,
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  author = {Bollen, Kenneth and Cacioppo, John T. and Krosnick, Jon A. and Olds, James L. and Kaplan, Robert M.},
  date = {2015},
  number = {Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences},
  institution = {{NSF}},
  keywords = {done}
}

@report{bollen2015a,
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  author = {Bollen, Kenneth and Cacioppo, John T. and Krosnick, Jon A. and Olds, James L. and Kaplan, Robert M.},
  date = {2015},
  number = {Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences},
  institution = {{NSF}},
  keywords = {done}
}

@report{bollenSocialBehavioralEconomic2015,
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  author = {Bollen, Kenneth and Cacioppo, John T. and Krosnick, Jon A. and Olds, James L. and Kaplan, Robert M.},
  date = {2015},
  number = {Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences},
  institution = {{NSF}},
  keywords = {done}
}

@report{bollenSocialBehavioralEconomic2015a,
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  author = {Bollen, Kenneth and Cacioppo, John T. and Krosnick, Jon A. and Olds, James L. and Kaplan, Robert M.},
  date = {2015},
  number = {Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences},
  institution = {{NSF}},
  keywords = {done}
}

@inproceedings{brase2009,
  title = {{{DataCite}} - {{A Global Registration Agency}} for {{Research Data}}},
  booktitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}}},
  author = {Brase, Jan},
  date = {2009-11},
  pages = {257--261},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/COINFO.2009.66},
  isbn = {978-0-7695-3898-3},
  keywords = {done}
}

@inproceedings{brase2009a,
  title = {{{DataCite}} - {{A Global Registration Agency}} for {{Research Data}}},
  booktitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}}},
  author = {Brase, Jan},
  date = {2009-11},
  pages = {257--261},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/COINFO.2009.66},
  isbn = {978-0-7695-3898-3},
  keywords = {done}
}

@inproceedings{brase2009b,
  title = {{{DataCite}} - {{A Global Registration Agency}} for {{Research Data}}},
  booktitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}}},
  author = {Brase, Jan},
  date = {2009-11},
  pages = {257--261},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/COINFO.2009.66},
  url = {http://ieeexplore.ieee.org/document/5361881/},
  urldate = {2020-09-11},
  eventtitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}} ({{COINFO}})},
  isbn = {978-0-7695-3898-3},
  file = {/Users/agwd/Zotero/storage/SHA7R8YI/Brase - 2009 - DataCite - A Global Registration Agency for Resear.pdf}
}

@inproceedings{braseDataCiteGlobalRegistration2009,
  title = {{{DataCite}} - {{A Global Registration Agency}} for {{Research Data}}},
  booktitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}}},
  author = {Brase, Jan},
  date = {2009-11},
  pages = {257--261},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/COINFO.2009.66},
  isbn = {978-0-7695-3898-3},
  keywords = {done}
}

@inproceedings{braseDataCiteGlobalRegistration2009a,
  title = {{{DataCite}} - {{A Global Registration Agency}} for {{Research Data}}},
  booktitle = {2009 {{Fourth International Conference}} on {{Cooperation}} and {{Promotion}} of {{Information Resources}} in {{Science}} and {{Technology}}},
  author = {Brase, Jan},
  date = {2009-11},
  pages = {257--261},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/COINFO.2009.66},
  isbn = {978-0-7695-3898-3},
  keywords = {done}
}

@online{breian,
  title = {Eksperter bekymret: To bekreftede tilfeller av mystisk soppsykdom i Norge},
  shorttitle = {Eksperter bekymret},
  author = {Breian, Åshild},
  url = {https://www.aftenposten.no/article/ap-zGOK8b.html},
  urldate = {2019-04-10},
  abstract = {Den mystiske soppinfeksjonen Candida auris er allerede påvist i Norge. Ekspert innrømmer at det kan skyldes flaks at ikke flere er blitt syke.},
  langid = {norsk},
  organization = {{Aftenposten}},
  file = {/Users/agwd/Zotero/storage/Z9N4CUGV/Eksperter-bekymret-To-bekreftede-tilfeller-av-mystisk-soppinfeksjon-i-Norge.html}
}

@report{broman2018,
  title = {Data Organization in Spreadsheets},
  author = {Broman, Karl W. and Woo, Kara H.},
  date = {2018-09-11},
  number = {e3183v2},
  institution = {{PeerJ Inc.}},
  issn = {2167-9843},
  doi = {10.7287/peerj.preprints.3183v2},
  url = {https://peerj.com/preprints/3183},
  urldate = {2020-12-04},
  abstract = {Spreadsheets are widely used software tools for data entry, storage, analysis, and visualization. Focusing on the data entry and storage aspects, this paper offers practical recommendations for organizing spreadsheet data to reduce errors and ease later analyses. The basic principles are: be consistent, write dates like YYYY-MM-DD, don't leave any cells empty, put just one thing in a cell, organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row), create a data dictionary, don't include calculations in the raw data files, don't use font color or highlighting as data, choose good names for things, make backups, use data validation to avoid data entry errors, and save the data in plain text files.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/T83RDAEH/Broman og Woo - 2018 - Data organization in spreadsheets.pdf;/Users/agwd/Zotero/storage/GNAJRUM3/3183.html}
}

@incollection{buckheit1995,
  title = {{{WaveLab}} and {{Reproducible Research}}},
  booktitle = {Wavelets and {{Statistics}}},
  author = {Buckheit, Jonathan B. and Donoho, David L.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Antoniadis, Anestis and Oppenheim, Georges},
  date = {1995},
  volume = {103},
  pages = {55--81},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-2544-7_5},
  abstract = {WaveLab is a library of Matlab routines for wavelet analysis, wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines.},
  isbn = {978-0-387-94564-4 978-1-4612-2544-7},
  langid = {english},
  keywords = {done}
}

@incollection{buckheit1995a,
  title = {{{WaveLab}} and {{Reproducible Research}}},
  booktitle = {Wavelets and {{Statistics}}},
  author = {Buckheit, Jonathan B. and Donoho, David L.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Antoniadis, Anestis and Oppenheim, Georges},
  date = {1995},
  volume = {103},
  pages = {55--81},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-2544-7_5},
  abstract = {WaveLab is a library of Matlab routines for wavelet analysis, wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines.},
  isbn = {978-0-387-94564-4 978-1-4612-2544-7},
  langid = {english},
  keywords = {done}
}

@incollection{buckheitWaveLabReproducibleResearch1995,
  title = {{{WaveLab}} and {{Reproducible Research}}},
  booktitle = {Wavelets and {{Statistics}}},
  author = {Buckheit, Jonathan B. and Donoho, David L.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Antoniadis, Anestis and Oppenheim, Georges},
  date = {1995},
  volume = {103},
  pages = {55--81},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-2544-7_5},
  abstract = {WaveLab is a library of Matlab routines for wavelet analysis, wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines.},
  isbn = {978-0-387-94564-4 978-1-4612-2544-7},
  langid = {english},
  keywords = {done}
}

@incollection{buckheitWaveLabReproducibleResearch1995a,
  title = {{{WaveLab}} and {{Reproducible Research}}},
  booktitle = {Wavelets and {{Statistics}}},
  author = {Buckheit, Jonathan B. and Donoho, David L.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Antoniadis, Anestis and Oppenheim, Georges},
  date = {1995},
  volume = {103},
  pages = {55--81},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-2544-7_5},
  abstract = {WaveLab is a library of Matlab routines for wavelet analysis, wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines.},
  isbn = {978-0-387-94564-4 978-1-4612-2544-7},
  langid = {english},
  keywords = {done}
}

@article{celebi2020,
  title = {Towards {{FAIR}} Protocols and Workflows: The {{OpenPREDICT}} Use Case},
  shorttitle = {Towards {{FAIR}} Protocols and Workflows},
  author = {Celebi, Remzi and Moreira, Joao Rebelo and Hassan, Ahmed A. and Ayyar, Sandeep and Ridder, Lars and Kuhn, Tobias and Dumontier, Michel},
  date = {2020-09-21},
  journaltitle = {PeerJ Computer Science},
  shortjournal = {PeerJ Comput. Sci.},
  volume = {6},
  pages = {e281},
  publisher = {{PeerJ Inc.}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.281},
  url = {https://peerj.com/articles/cs-281},
  urldate = {2020-12-04},
  abstract = {It is essential for the advancement of science that researchers share, reuse and reproduce each other’s workflows and protocols. The FAIR principles are a set of guidelines that aim to maximize the value and usefulness of research data, and emphasize the importance of making digital objects findable and reusable by others. The question of how to apply these principles not just to data but also to the workflows and protocols that consume and produce them is still under debate and poses a number of challenges. In this paper we describe a two-fold approach of simultaneously applying the FAIR principles to scientific workflows as well as the involved data. We apply and evaluate our approach on the case of the PREDICT workflow, a highly cited drug repurposing workflow. This includes FAIRification of the involved datasets, as well as applying semantic technologies to represent and store data about the detailed versions of the general protocol, of the concrete workflow instructions, and of their execution traces. We propose a semantic model to address these specific requirements and was evaluated by answering competency questions. This semantic model consists of classes and relations from a number of existing ontologies, including Workflow4ever, PROV, EDAM, and BPMN. This allowed us then to formulate and answer new kinds of competency questions. Our evaluation shows the high degree to which our FAIRified OpenPREDICT workflow now adheres to the FAIR principles and the practicality and usefulness of being able to answer our new competency questions.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/JHDV5I6Y/Celebi et al. - 2020 - Towards FAIR protocols and workflows the OpenPRED.pdf;/Users/agwd/Zotero/storage/8NLLHRDU/cs-281.html}
}

@online{centerforhistoryandnewmedia,
  title = {Rask Innføring},
  author = {{Center for History and New Media}},
  url = {http://zotero.org/support/quick_start_guide}
}

@article{chakravarty2019,
  title = {Inequality and Welfare: {{Some}} Axiomatic Characterizations},
  shorttitle = {Inequality and Welfare},
  author = {Chakravarty, Satya R. and Chattopadhyay, Nachiketa and Qingbin, Liu},
  date = {2019-06},
  journaltitle = {International Journal of Economic Theory},
  shortjournal = {Int. J. Econ. Theory},
  volume = {15},
  number = {2},
  pages = {153--168},
  issn = {1742-7355},
  doi = {10.1111/ijet.12169},
  abstract = {We characterize social welfare functions, which, under ceteris paribus assumptions, rank income distributions in exactly the same way as the negative of the Atkinson, Kolm-Pollak, and Theil mean logarithmic deviation indices of inequality of income distributions. While the first two characterizations rely on a general social welfare function, the third employs the symmetric utilitarian structure of the welfare function. Implications of several subsets of the set of axioms considered in the paper are also investigated.},
  langid = {english},
  keywords = {Atkinson index,characterization,components,efficiency,equity,gini indexes,inequality,Kolm-Pollak index,polarization,ranking,social   welfare,social-welfare,Theil index},
  annotation = {WOS:000467463100002}
}

@article{chelley-steeley2011,
  title = {Intraday Patterns in {{London}} Listed {{Exchange Traded Funds}}},
  author = {Chelley-Steeley, Patricia and Park, Keebong},
  date = {2011-10-01},
  journaltitle = {International Review of Financial Analysis},
  shortjournal = {International Review of Financial Analysis},
  volume = {20},
  number = {5},
  pages = {244--251},
  issn = {1057-5219},
  doi = {10.1016/j.irfa.2011.05.001},
  url = {http://www.sciencedirect.com/science/article/pii/S1057521911000482},
  urldate = {2020-05-07},
  abstract = {In this paper we examine the intraday trading patterns of Exchange Traded Funds (ETFs) listed on the London Stock Exchange. ETFs have been shown to be characterised by much lower bid–ask spread costs and by lower levels of information asymmetry than individual securities. One possible explanation for intraday trading patterns is that concentration of trading arises at the start of the trading day because informed traders have private information that quickly diminishes in value as trading progresses. Since ETFs have lower trading costs and lower levels of information asymmetry we would expect these securities to display less pronounced intraday patterns than individual securities. We fail to find that ETFs are characterised by concentrated trading bouts during the day and therefore find support for the argument that information asymmetry is the cause of intraday volume patterns in stock markets. We find that ETF bid–ask spreads and volatility are elevated at the open but not at the close. This lends support to the “accumulation of information” explanation that sees high spreads and volatility at the open as a consequence of information accumulating during a market closure and impacting on the market when it next opens.},
  langid = {english},
  keywords = {Intraday trading patterns,London,Spread},
  file = {/Users/agwd/Zotero/storage/C5I9XGJJ/S1057521911000482.html}
}

@article{chin2003,
  title = {A Critical Review of Literature on the Hedonic Price Model},
  author = {Chin, TL and Chau, KW},
  date = {2003},
  journaltitle = {International Journal for Housing Science and Its Applications},
  volume = {27},
  number = {2},
  pages = {145--165},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{collaboration2015,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Collaboration, Open Science},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{collaboration2015a,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Collaboration, Open Science},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{collaborationEstimatingReproducibilityPsychological2015,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Collaboration, Open Science},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{collaborationEstimatingReproducibilityPsychological2015a,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Collaboration, Open Science},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@book{conyers,
  title = {Learn {{Git}} in 3 {{Hours}}},
  author = {Conyers, Ross},
  abstract = {Build powerful and effective projects using Git Version Control Systems About This Video Learn how to create, contribute to, and collaborate on software projects using Git Understand its fundamental features,...}
}

@book{conyersa,
  title = {Learn {{Git}} in 3 {{Hours}}},
  author = {Conyers, Ross},
  abstract = {Build powerful and effective projects using Git Version Control Systems About This Video Learn how to create, contribute to, and collaborate on software projects using Git Understand its fundamental features,...}
}

@online{conyersb,
  title = {Learn {{Git}} in 3 {{Hours}}},
  author = {Conyers, Ross},
  url = {https://www.safaribooksonline.com/videos/learn-git-in/9781789348231/9781789348231-video1_2},
  urldate = {2020-03-30},
  abstract = {Build powerful and effective projects using Git Version Control Systems About This Video Learn how to create, contribute to, and collaborate on software projects using Git Understand its fundamental features,...},
  organization = {{O'Reilly | Safari}},
  file = {/Users/agwd/Zotero/storage/MHMHVXU5/9781789348231-video2_10.html}
}

@book{conyersLearnGitHours,
  title = {Learn {{Git}} in 3 {{Hours}}},
  author = {Conyers, Ross},
  abstract = {Build powerful and effective projects using Git Version Control Systems About This Video Learn how to create, contribute to, and collaborate on software projects using Git Understand its fundamental features,...}
}

@book{conyersLearnGitHoursa,
  title = {Learn {{Git}} in 3 {{Hours}}},
  author = {Conyers, Ross},
  abstract = {Build powerful and effective projects using Git Version Control Systems About This Video Learn how to create, contribute to, and collaborate on software projects using Git Understand its fundamental features,...}
}

@article{coulson1992,
  title = {Semiparametric Estimates of the Marginal Price of Floorspace},
  author = {Coulson, NE},
  date = {1992},
  journaltitle = {Journal of Real Estate Finance and Economics},
  volume = {5},
  number = {1},
  pages = {73--83},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@report{cowell2003,
  title = {Theil, {{Inequality}} and the {{Structure}} of {{Income Distribution}}},
  author = {Cowell, Frank A.},
  date = {2003-05},
  series = {{{STICERD}} - {{Distributional Analysis Research Programme Papers}}},
  number = {67},
  institution = {{Suntory and Toyota International Centres for Economics and Related Disciplines, LSE}},
  url = {https://ideas.repec.org/p/cep/stidar/67.html},
  urldate = {2019-09-13},
  abstract = {This paper documents the impact of Argentina's recent economic crises on different aspects of poverty, with a special focus on the economic collapse of 2002. We discuss the methodology of poverty measurement in Argentina and we use a simple rule to compensate for the lack of regional poverty figures until 2001, providing consistent series of urban poverty estimates at the national and regional levels. We then present series of short term dynamics of poverty, decomposing the changes in every period of time with panel data. Finally, we analyse the determinants of poverty, with a focus on accounting for observed differences in income (and thereby poverty) between October 2001 and May 2002. Among other conclusions, we find in our decomposition analysis that households without the means to diversify their income sources suffered more than others from the crisis of 2002.},
  langid = {english},
  keywords = {homotheticity,independence,inequality,Theil,translatability.},
  file = {/Users/agwd/Zotero/storage/LPUDPKE2/Cowell - 2003 - Theil, Inequality and the Structure of Income Dist.pdf;/Users/agwd/Zotero/storage/ZAXMYNRJ/67.html}
}

@book{DearColleagueLetter,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{DearColleagueLettera,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{DearColleagueLetterb,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{DearColleagueLetterc,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@article{dewald1986,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  shorttitle = {Replication in {{Empirical Economics}}},
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  date = {1986},
  journaltitle = {The American Economic Review},
  volume = {76},
  number = {4},
  pages = {587--603},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence.},
  keywords = {done}
}

@article{dewald1986a,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  shorttitle = {Replication in {{Empirical Economics}}},
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  date = {1986},
  journaltitle = {The American Economic Review},
  volume = {76},
  number = {4},
  pages = {587--603},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence.},
  keywords = {done}
}

@article{dewald1986b,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  shorttitle = {Replication in {{Empirical Economics}}},
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  date = {1986},
  journaltitle = {The American Economic Review},
  volume = {76},
  number = {4},
  eprint = {1806061},
  eprinttype = {jstor},
  pages = {587--603},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence.}
}

@article{dewald2020,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  author = {Dewald, William G and Thursby, Jerry G and Anderson, Richard G},
  date = {2020},
  pages = {18},
  langid = {english},
  keywords = {done}
}

@article{dewald2020a,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  author = {Dewald, William G and Thursby, Jerry G and Anderson, Richard G},
  date = {2020},
  pages = {18},
  langid = {english},
  keywords = {done}
}

@article{dewald2020b,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  author = {Dewald, William G and Thursby, Jerry G and Anderson, Richard G},
  date = {2020},
  pages = {18},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/B5HSUWH5/Dewald et al. - 2020 - Replication in Empirical Economics The Journal of.pdf}
}

@article{dewaldReplicationEmpiricalEconomics1986,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  shorttitle = {Replication in {{Empirical Economics}}},
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  date = {1986},
  journaltitle = {The American Economic Review},
  volume = {76},
  number = {4},
  pages = {587--603},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence.},
  keywords = {done}
}

@article{dewaldReplicationEmpiricalEconomics1986a,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  shorttitle = {Replication in {{Empirical Economics}}},
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  date = {1986},
  journaltitle = {The American Economic Review},
  volume = {76},
  number = {4},
  pages = {587--603},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  abstract = {This paper examines the role of replication in empirical economic research. It presents the findings of a two-year study that collected programs and data from authors and attempted to replicate their published results. Our research provides new and important information about the extent and causes of failures to replicate published results in economics. Our findings suggest that inadvertent errors in published empirical articles are a commonplace rather thana rare occurrence.},
  keywords = {done}
}

@article{dewaldReplicationEmpiricalEconomics2020,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  author = {Dewald, William G and Thursby, Jerry G and Anderson, Richard G},
  date = {2020},
  pages = {18},
  langid = {english},
  keywords = {done}
}

@article{dewaldReplicationEmpiricalEconomics2020a,
  title = {Replication in {{Empirical Economics}}: {{The Journal}} of {{Money}}, {{Credit}} and {{Banking Project}}},
  author = {Dewald, William G and Thursby, Jerry G and Anderson, Richard G},
  date = {2020},
  pages = {18},
  langid = {english},
  keywords = {done}
}

@article{donofrio2019,
  title = {Infrastructures and {{Income Inequality}}: {{The Case}} of {{Italian Provinces}}},
  shorttitle = {Infrastructures and {{Income Inequality}}},
  author = {D'Onofrio, Alexandra and Giordani, Paolo E.},
  date = {2019-04},
  journaltitle = {Politica Economica},
  shortjournal = {Politi. Econ.},
  volume = {35},
  number = {1},
  pages = {27--54},
  issn = {1120-9496},
  doi = {10.1429/93306},
  abstract = {This paper studies the relation between infrastructure endowment and income inequality across Italian provinces over the period 2001-2015. Using data from the Ministero dell'Economia e Finanza (MEF), we construct measures of income inequality for each province (Gini index and Theil index). The stock of infrastructures by province is measured by a set of indicators of physical endowments built by the Istituto Tagliacarne. The empirical analysis confirms the existence of a negative effect of the total infrastructure endowment on income inequality. This effect is mainly driven by transport and energy infrastructures. In contrast, other sub-components of infrastructure endowment, such as technological and banking infrastructures as well as cultural/entertainment networks, accentuate income inequality. We then show that infrastructures have a positive effect on the incomes of both the relatively poor classes (20\% poorest class), the median and the richest class (10\% richest), while they have no effect on the poorest 10\% of the population. Finally, a north/south analysis of Italy suggests that the infrastructure deficit of the southern provinces might play a role in explaining their higher income inequality compared to the northern provinces.},
  langid = {english},
  keywords = {growth,income distribution,infrastructure endowment,Italian provinces,panel-data,public-goods},
  annotation = {WOS:000468818600002}
}

@article{dubin1992,
  title = {Spatial Autocorrelation and Neighbourhood Quality},
  author = {Dubin, RA},
  date = {1992},
  journaltitle = {Regional Science and Urban Economics, Vol},
  volume = {22},
  number = {3},
  pages = {433--452},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{durand2011,
  title = {Fear and the {{Fama}}-{{French Factors}}},
  author = {Durand, Robert B. and Lim, Dominic and Zumwalt, J. Kenton},
  date = {2011},
  journaltitle = {Financial Management},
  volume = {40},
  number = {2},
  eprint = {41237910},
  eprinttype = {jstor},
  pages = {409--426},
  issn = {0046-3892},
  abstract = {Investors' expectations of market volatility, captured by the VIX (the Chicago Board Options Exchange's volatility index, also known as the "investor fear gauge"), affects the expected returns of US equities. Changes in the VIX drive variations in the expected returns of the factors included in the Fama and French three-factor model augmented with a momentum factor. The market risk premium (R m -R f ) and the value premium (HML) are especially sensitive to changes in the VIX. An increase in expected volatility is associated with flights to quality and increases in estimated required returns.}
}

@article{eliasson2001,
  title = {Transport and {{Location Effects}} of {{Road Pricing}}: {{A Simulation Approach}}},
  shorttitle = {Transport and {{Location Effects}} of {{Road Pricing}}},
  author = {Eliasson, Jonas and Mattsson, Lars-Göran},
  date = {2001},
  journaltitle = {Journal of Transport Economics and Policy},
  volume = {35},
  number = {3},
  eprint = {20053883},
  eprinttype = {jstor},
  pages = {417--456},
  issn = {0022-5258},
  abstract = {The effects of road pricing on transport and location patterns have been much discussed. However, it is unclear how large the effects are, and whether relocation of households, workplaces and shops will counteract or amplify the effects on transport. In this paper a model of a generic symmetric city is developed. The model is used to investigate the effects of road pricing in the form of congestion pricing and a toll ring. The results indicate that the impacts on location are small compared to the impacts on traffic volumes, modal split, and trip distances. The different effects of congestion pricing and toll rings at different positions are considered.},
  file = {/Users/agwd/Zotero/storage/7DDQ96ZF/Eliasson and Mattsson - 2001 - Transport and Location Effects of Road Pricing A .pdf}
}

@report{ellis2017,
  title = {How to Share Data for Collaboration},
  author = {Ellis, Shannon E. and Leek, Jeffrey T.},
  date = {2017-09-01},
  number = {e3139v5},
  institution = {{PeerJ Inc.}},
  issn = {2167-9843},
  doi = {10.7287/peerj.preprints.3139v5},
  url = {https://peerj.com/preprints/3139},
  urldate = {2020-12-04},
  abstract = {Within the statistics community, a number of guiding principles for sharing data have emerged; however, these principles are not always made clear to collaborators generating the data. To bridge this divide, we have established a set of guidelines for sharing data. In these, we highlight the need to provide raw data to the statistician, the importance of consistent formatting, and the necessity of including all essential experimental information and pre-processing steps carried out to the statistician. With these guidelines we hope to avoid errors and delays in data analysis.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/WRECAJG3/Ellis og Leek - 2017 - How to share data for collaboration.pdf;/Users/agwd/Zotero/storage/SW5Z88QP/3139v5.html}
}

@article{elmenreich2019,
  title = {Making Simulation Results Reproducible—{{Survey}}, Guidelines, and Examples Based on {{Gradle}} and {{Docker}}},
  author = {Elmenreich, Wilfried and Moll, Philipp and Theuermann, Sebastian and Lux, Mathias},
  date = {2019-12-09},
  journaltitle = {PeerJ Computer Science},
  shortjournal = {PeerJ Comput. Sci.},
  volume = {5},
  pages = {e240},
  publisher = {{PeerJ Inc.}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.240},
  url = {https://peerj.com/articles/cs-240},
  urldate = {2020-12-04},
  abstract = {This article addresses two research questions related to reproducibility within the context of research related to computer science. First, a survey on reproducibility addressed to researchers in the academic and private sectors is described and evaluated. The survey indicates a strong need for open and easily accessible results, in particular, reproducing an experiment should not require too much effort. The results of the survey are then used to formulate guidelines for making research results reproducible. In addition, this article explores four approaches based on software tools that could bring forward reproducibility in research results. After a general analysis of tools, three examples are further investigated based on actual research projects which are used to evaluate previously introduced tools. Results indicate that the evaluated tools contribute well to making simulation results reproducible but due to conflicting requirements, none of the presented solutions fulfills all intended goals perfectly.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/IMLYFYJG/Elmenreich et al. - 2019 - Making simulation results reproducible—Survey, gui.pdf;/Users/agwd/Zotero/storage/G2VFVKU3/cs-240.html}
}

@article{ezekiel1933,
  title = {Some {{Considerations}} on the {{Analysis}} of the {{Prices}} of {{Competing}} or {{Substitute Commodities}}},
  author = {Ezekiel, Mordecai},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {2},
  pages = {172--180},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{ezekiel1933a,
  title = {Some {{Considerations}} on the {{Analysis}} of the {{Prices}} of {{Competing}} or {{Substitute Commodities}}},
  author = {Ezekiel, Mordecai},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {2},
  pages = {172--180},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{ezekiel1933b,
  title = {Some Considerations on the Analysis of the Prices of Competing or Substitute Commodities},
  author = {Ezekiel, Mordecai},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {2},
  eprint = {1907091},
  eprinttype = {jstor},
  pages = {172--180},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262}
}

@article{ezekielConsiderationsAnalysisPrices1933,
  title = {Some {{Considerations}} on the {{Analysis}} of the {{Prices}} of {{Competing}} or {{Substitute Commodities}}},
  author = {Ezekiel, Mordecai},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {2},
  pages = {172--180},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{ezekielConsiderationsAnalysisPrices1933a,
  title = {Some {{Considerations}} on the {{Analysis}} of the {{Prices}} of {{Competing}} or {{Substitute Commodities}}},
  author = {Ezekiel, Mordecai},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {2},
  pages = {172--180},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{fama1991,
  title = {Efficient {{Capital Markets}}: {{II}}},
  shorttitle = {Efficient {{Capital Markets}}},
  author = {Fama, Eugene F.},
  date = {1991},
  journaltitle = {The Journal of Finance},
  volume = {46},
  number = {5},
  eprint = {2328565},
  eprinttype = {jstor},
  pages = {1575--1617},
  issn = {0022-1082},
  doi = {10.2307/2328565},
  file = {/Users/agwd/Zotero/storage/Y2ZKBBD5/Fama - 1991 - Efficient Capital Markets II.pdf}
}

@article{farber2013,
  title = {The Social Interaction Potential of Metropolitan Regions: A Time-Geographic Measurement Approach Using Joint Accessibility},
  author = {Farber, S and Neutens, T and Miller, H J and Li, X},
  date = {2013},
  journaltitle = {Annals of the Association of Americam Geographers},
  pages = {483--504},
  date-added = {2020-01-09 15:04:44 +0100},
  date-modified = {2020-01-09 15:06:20 +0100},
  keywords = {ocp022019_REGION_template}
}

@report{florax2003,
  title = {Misspecification in Linear Spatial Regression Models},
  author = {Florax, RJGM and Nijkamp, P},
  date = {2003},
  institution = {{Tinbergen Institute Discussion Paper, (TI 2003-081/3)}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{fomel2009,
  title = {Guest {{Editors}}' {{Introduction}}: {{Reproducible Research}}},
  author = {Fomel, S. and Claerbout, J. F.},
  date = {2009},
  journaltitle = {Computing in Science Engineering},
  volume = {11},
  number = {1},
  pages = {5--7},
  keywords = {done}
}

@article{fomel2009a,
  title = {Guest {{Editors}}' {{Introduction}}: {{Reproducible Research}}},
  author = {Fomel, S. and Claerbout, J. F.},
  date = {2009},
  journaltitle = {Computing in Science Engineering},
  volume = {11},
  number = {1},
  pages = {5--7},
  keywords = {done}
}

@article{fomelGuestEditorsIntroduction2009,
  title = {Guest {{Editors}}' {{Introduction}}: {{Reproducible Research}}},
  author = {Fomel, S. and Claerbout, J. F.},
  date = {2009},
  journaltitle = {Computing in Science Engineering},
  volume = {11},
  number = {1},
  pages = {5--7},
  keywords = {done}
}

@article{fomelGuestEditorsIntroduction2009a,
  title = {Guest {{Editors}}' {{Introduction}}: {{Reproducible Research}}},
  author = {Fomel, S. and Claerbout, J. F.},
  date = {2009},
  journaltitle = {Computing in Science Engineering},
  volume = {11},
  number = {1},
  pages = {5--7},
  keywords = {done}
}

@article{foster1983,
  title = {An Axiomatic Characterization of the {{Theil}} Measure of Income Inequality},
  author = {Foster, James E},
  date = {1983-10-01},
  journaltitle = {Journal of Economic Theory},
  shortjournal = {Journal of Economic Theory},
  volume = {31},
  number = {1},
  pages = {105--121},
  issn = {0022-0531},
  doi = {10.1016/0022-0531(83)90023-6},
  url = {http://www.sciencedirect.com/science/article/pii/0022053183900236},
  urldate = {2019-09-13},
  abstract = {This paper provides a characterization of a frequently used measure of income inequality. It has been known for some time that the Theil measure of income inequality (1) is consistent with the Lorenz criterion, when it applies, and (2) exhibits a simple and empricically useful decomposition by population subgroup into within-group and between-group terms. The major theorem establishes the converse: the decomposability property defines the Theil measure uniquely (up to a positive multiple) among all Lorenz-consistent measures.},
  file = {/Users/agwd/Zotero/storage/I5EBIRAL/0022053183900236.html}
}

@article{fotheringham1983,
  title = {A New Set of Spatial Interaction Models: The Theory of Competing Destinations},
  author = {Fotheringham, A S},
  date = {1983},
  journaltitle = {Environment and Planning A},
  volume = {15},
  pages = {1121--1132},
  date-added = {2015-10-20 11:35:51 +0000},
  date-modified = {2015-10-20 11:36:52 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{frankel2011,
  title = {Measuring School Segregation},
  author = {Frankel, David M. and Volij, Oscar},
  date = {2011-01-01},
  journaltitle = {Journal of Economic Theory},
  shortjournal = {Journal of Economic Theory},
  volume = {146},
  number = {1},
  pages = {1--38},
  issn = {0022-0531},
  doi = {10.1016/j.jet.2010.10.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0022053110001353},
  urldate = {2019-09-13},
  abstract = {Using only ordinal axioms, we characterize several multigroup school segregation indices: the Atkinson indices for the class of school districts with a given fixed number of ethnic groups and the Mutual Information index for the class of all districts. Properties of other school segregation indices are also discussed. In an empirical application, we document a weakening of the effect of ethnicity on school assignment from 1987/1988 to 2007/2008. We also show that segregation between districts within cities currently accounts for 33\% of total segregation. Segregation between states, driven mainly by the distinct residential patterns of Hispanics, contributes another 32\%.},
  keywords = {Axiomatic method,Education,Indices,Measurement,Schools,Segregation},
  file = {/Users/agwd/Zotero/storage/V5NENWNG/Frankel and Volij - 2011 - Measuring school segregation.pdf;/Users/agwd/Zotero/storage/RT2SYEKQ/S0022053110001353.html}
}

@article{frisch1933,
  title = {Editor's {{Note}}},
  author = {Frisch, Ragnar},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {1},
  pages = {1--4},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{frisch1933a,
  title = {Editor's {{Note}}},
  author = {Frisch, Ragnar},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {1},
  pages = {1--4},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{frischEditorNote1933,
  title = {Editor's {{Note}}},
  author = {Frisch, Ragnar},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {1},
  pages = {1--4},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@article{frischEditorNote1933a,
  title = {Editor's {{Note}}},
  author = {Frisch, Ragnar},
  date = {1933},
  journaltitle = {Econometrica},
  volume = {1},
  number = {1},
  pages = {1--4},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {00129682, 14680262},
  keywords = {done}
}

@book{gastineau2002,
  title = {The {{Exchange}}-{{Traded Funds Manual}}},
  author = {Gastineau, Gary L.},
  date = {2002-02-14},
  eprint = {CIYoyIrP6cIC},
  eprinttype = {googlebooks},
  publisher = {{John Wiley \& Sons}},
  abstract = {Praise for the exchange-traded funds manual  "Exchange-traded funds are the hottest finance innovation of the past decade. Gary Gastineau, who played a critical role in their development, demystifies the working of these instruments, lucidly describes their advantages and disadvantages, and guides investors on their use. This gem of a book will be the ETF bible for years to come."  -Burton Malkiel, Chemical Bank Chairman's Professor of Economics, Princeton University  "This is the first comprehensive book on exchange-traded funds.The author displays an institutional and practical knowledge of exchange-traded funds that makes this book necessary reading for not only the knowledgeable investor but for the professional researcher seeking to understand these relatively new investment vehicles."  -Martin J. Gruber, Nomura Professor of Finance Stern School of Business, New York University  "Gary Gastineau is a national treasure. Exchange-traded funds are the wave of the future, and Gary has been instrumental in their development from day one. His knowledge is encyclopedic, and his style and subtle humor make it all accessible to the reader."  -Wayne H. Wagner, Chairman, Plexus Group, Inc.  "In Gary Gastineau's brilliant work in illuminating the reader on exchange-traded funds, he provides rich insights into the process and methodology of adding value and cites a convergence of market forces that creates a compelling story for the use of ETFs for those who choose to add value."  -Stephen C. Winks, Publisher, Senior Consultant  "The introduction of exchange-traded funds was one of the success stories of  Wall Street in the 1990s. Gary Gastineau was a key contributor to this success, and his book is an important benchmark on both the current status of this important new category and the vast potential of its next-generation products."  -Salvatore Sodano, Chairman and Chief Executive Officer American Stock Exchange},
  isbn = {978-0-471-21894-4},
  langid = {english},
  pagetotal = {432},
  keywords = {Business & Economics / General,Business & Economics / Investments & Securities / General}
}

@article{gentleman2003,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Temple Lang, Duncan},
  date = {2003},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186007X178663},
  url = {http://www.tandfonline.com/doi/abs/10.1198/106186007X178663},
  urldate = {2020-08-23},
  abstract = {For various reasons, it is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, etc. with the documents that describe and rely on them. This integration allows readers to both verify and adapt the statements in the documents. Authors can easily reproduce them in the future, and they can present the document’s contents in a different medium, e.g. with interactive controls. This paper describes a software framework for authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents, including figures, tables, etc., can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/Y5EX8QC9/Gentleman og Temple Lang - 2007 - Statistical Analyses and Reproducible Research.pdf}
}

@article{gentleman2004,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Lang, Duncan Temple},
  date = {2004-05-29},
  journaltitle = {Bioconductor Project Working Papers},
  url = {https://biostats.bepress.com/bioconductor/paper2},
  file = {/Users/agwd/Zotero/storage/H6NNTZSG/paper2.html}
}

@article{gentleman2005,
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Gentleman, Robert},
  date = {2005-01-11},
  journaltitle = {Statistical Applications in Genetics and Molecular Biology},
  volume = {4},
  number = {1},
  issn = {1544-6115, 2194-6302},
  doi = {10.2202/1544-6115.1034},
  url = {https://www.degruyter.com/view/j/sagmb.2005.4.issue-1/sagmb.2005.4.1.1034/sagmb.2005.4.1.1034.xml},
  urldate = {2020-08-19},
  abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2004), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output – thereby providing the familiar, but limited, static document.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/MYIWFKH4/Gentleman - 2005 - Reproducible Research A Bioinformatics Case Study.pdf}
}

@article{gentleman2005a,
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Gentleman, Robert},
  date = {2005-01},
  journaltitle = {Statistical Applications in Genetics and Molecular Biology},
  volume = {4},
  number = {1},
  issn = {1544-6115, 2194-6302},
  doi = {10.2202/1544-6115.1034},
  abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2004), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output – thereby providing the familiar, but limited, static document.},
  langid = {english},
  keywords = {done}
}

@article{gentleman2005b,
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Gentleman, Robert},
  date = {2005-01},
  journaltitle = {Statistical Applications in Genetics and Molecular Biology},
  volume = {4},
  number = {1},
  issn = {1544-6115, 2194-6302},
  doi = {10.2202/1544-6115.1034},
  abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2004), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output – thereby providing the familiar, but limited, static document.},
  langid = {english},
  keywords = {done}
}

@article{gentleman2007,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Lang, Duncan Temple},
  date = {2007},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/106186007X178663},
  abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents— including figures, tables, and so on— can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
  keywords = {done}
}

@article{gentleman2007a,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Lang, Duncan Temple},
  date = {2007},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/106186007X178663},
  abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents— including figures, tables, and so on— can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
  keywords = {done}
}

@article{gentleman2007b,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Temple Lang, Duncan},
  date = {2007-03},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186007X178663},
  url = {http://www.tandfonline.com/doi/abs/10.1198/106186007X178663},
  urldate = {2020-08-20},
  abstract = {For various reasons, it is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, etc. with the documents that describe and rely on them. This integration allows readers to both verify and adapt the statements in the documents. Authors can easily reproduce them in the future, and they can present the document’s contents in a different medium, e.g. with interactive controls. This paper describes a software framework for authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents, including figures, tables, etc., can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/4P85W3K8/Gentleman og Temple Lang - 2007 - Statistical Analyses and Reproducible Research.pdf}
}

@article{gentlemanReproducibleResearchBioinformatics2005,
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Gentleman, Robert},
  date = {2005-01},
  journaltitle = {Statistical Applications in Genetics and Molecular Biology},
  volume = {4},
  number = {1},
  issn = {1544-6115, 2194-6302},
  doi = {10.2202/1544-6115.1034},
  abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2004), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output – thereby providing the familiar, but limited, static document.},
  langid = {english},
  keywords = {done}
}

@article{gentlemanReproducibleResearchBioinformatics2005a,
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  shorttitle = {Reproducible {{Research}}},
  author = {Gentleman, Robert},
  date = {2005-01},
  journaltitle = {Statistical Applications in Genetics and Molecular Biology},
  volume = {4},
  number = {1},
  issn = {1544-6115, 2194-6302},
  doi = {10.2202/1544-6115.1034},
  abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2004), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output – thereby providing the familiar, but limited, static document.},
  langid = {english},
  keywords = {done}
}

@article{gentlemanStatisticalAnalysesReproducible2007,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Lang, Duncan Temple},
  date = {2007},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/106186007X178663},
  abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents— including figures, tables, and so on— can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
  keywords = {done}
}

@article{gentlemanStatisticalAnalysesReproducible2007a,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {Gentleman, Robert and Lang, Duncan Temple},
  date = {2007},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1--23},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/106186007X178663},
  abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents— including figures, tables, and so on— can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
  keywords = {done}
}

@article{gitlesen2000,
  title = {A Competing Destinations Approach to Modeling Commuting Flows: {{A}} Theoretical Interpretation and an Empirical Application of the Model},
  author = {Gitlesen, J P and Thorsen, I},
  date = {2000},
  journaltitle = {Environment and Planning A},
  volume = {32},
  pages = {2057--2074},
  date-added = {2015-10-20 11:33:42 +0000},
  date-modified = {2015-10-20 11:35:44 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{gjerde2014,
  title = {Børshandlede produkter: ETP, ETF og ETN},
  shorttitle = {Børshandlede produkter},
  author = {Gjerde, Øystein and Sættem, Frode},
  date = {2014},
  journaltitle = {Praktisk økonomi \& finans},
  volume = {30},
  number = {04},
  pages = {367--380},
  publisher = {{Universitetsforlaget}},
  issn = {1504-2871, 1501-0074},
  url = {https://www.idunn.no/pof/2014/04/boershandlede_produkter_etp_etf_og_etn},
  urldate = {2020-05-07},
  abstract = {Børshandlede produkter (ETP - Exchange Traded Products) må kunne omtales som en av de mest populære finansielle innovasjoner i løpet av de to siste tiårene. I denne artikkelen redegjør vi for de to hovedgruppene av børshandlede produkter, børshandlede fond (ETF - Exchange Traded Funds) og børshandlede verdipapirer (ETN - Exchange Traded Notes). I det norske markedet finnes det en rekke ETF- og ETN-produkter knyttet til OBX-indeksen. Vi dokumenterer at disse produktene har en lavere avkastningsmultippel målt mot indeksen enn hva produktene lover. Vi viser dessuten at likviditeten i de fleste ETP-produktene på Oslo Børs er svært tynn. Som bakteppe redegjør vi først kortfattet for sentrale forklaringsfaktorer for finansiell innovasjon og ulike kriterier som må være oppfylte for at nyskapninger i finansmarkedet skal bli en suksess.},
  langid = {norwegian},
  file = {/Users/agwd/Zotero/storage/GBSAB6TF/Gjerde og Sættem - 2014 - Børshandlede produkter ETP, ETF og ETN.pdf;/Users/agwd/Zotero/storage/ZILJRIEB/boershandlede_produkter_etp_etf_og_etn.html}
}

@article{gjestland2014,
  title = {The Suitability of Hedonic Models for Cost-Benefit Analysis: {{Evidence}} from Commuting Flows},
  author = {Gjestland, A and McArthur, D and Osland, L and Thorsen, I},
  date = {2014},
  journaltitle = {Transportation Research Part A: Policy and Practice},
  volume = {61},
  pages = {136--151},
  date-added = {2015-10-20 11:35:51 +0000},
  date-modified = {2015-10-20 11:36:52 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{golub1999,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}} and {{Class Prediction}} by {{Gene Expression Monitoring}}},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10},
  journaltitle = {Science (New York, N.Y.)},
  volume = {286},
  number = {5439},
  eprint = {10521349},
  eprinttype = {pmid},
  pages = {531--537},
  issn = {0036-8075},
  doi = {10.1126/science.286.5439.531},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  keywords = {done}
}

@article{golub1999a,
  title = {Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Monitoring},
  shorttitle = {Molecular Classification of Cancer},
  author = {Golub, T.R. and Slonim, D.K. and Tamayo, Pablo and Huard, C and Gaasenbeek, M and Mesirov, J.P. and Coller, Hilary and Loh, Mignon and Downing, J.R. and Caligiuri, Michael and Bloomfield, C and Lander, E},
  date = {1999-11-01},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science (New York, N.Y.)},
  volume = {286},
  pages = {531--7},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  file = {/Users/agwd/Zotero/storage/BMLJH6NJ/Golub et al. - 1999 - Molecular classification of cancer class discover.pdf}
}

@article{golub1999b,
  title = {Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring},
  shorttitle = {Molecular Classification of Cancer},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10-15},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {286},
  number = {5439},
  eprint = {10521349},
  eprinttype = {pmid},
  pages = {531--537},
  issn = {0036-8075},
  doi = {10.1126/science.286.5439.531},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  keywords = {Acute Disease,Antineoplastic Combined Chemotherapy Protocols,Cell Adhesion,Cell Cycle,Gene Expression Profiling,Homeodomain Proteins,Humans,Leukemia; Myeloid,Neoplasm Proteins,Neoplasms,Oligonucleotide Array Sequence Analysis,Oncogenes,Precursor Cell Lymphoblastic Leukemia-Lymphoma,Predictive Value of Tests,Reproducibility of Results,Treatment Outcome},
  file = {/Users/agwd/Zotero/storage/JYT7X2JI/Golub et al. - 1999 - Molecular classification of cancer class discover.pdf}
}

@article{golub1999c,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}} and {{Class Prediction}} by {{Gene Expression Monitoring}}},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10},
  journaltitle = {Science (New York, N.Y.)},
  volume = {286},
  number = {5439},
  eprint = {10521349},
  eprinttype = {pmid},
  pages = {531--537},
  issn = {0036-8075},
  doi = {10.1126/science.286.5439.531},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  keywords = {done}
}

@article{golubMolecularClassificationCancer1999,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}} and {{Class Prediction}} by {{Gene Expression Monitoring}}},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10},
  journaltitle = {Science (New York, N.Y.)},
  volume = {286},
  number = {5439},
  eprint = {10521349},
  eprinttype = {pmid},
  pages = {531--537},
  issn = {0036-8075},
  doi = {10.1126/science.286.5439.531},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  keywords = {done}
}

@article{golubMolecularClassificationCancer1999a,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}} and {{Class Prediction}} by {{Gene Expression Monitoring}}},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10},
  journaltitle = {Science (New York, N.Y.)},
  volume = {286},
  number = {5439},
  eprint = {10521349},
  eprinttype = {pmid},
  pages = {531--537},
  issn = {0036-8075},
  doi = {10.1126/science.286.5439.531},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  keywords = {done}
}

@article{goodman2016,
  title = {What Does Research Reproducibility Mean?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  date = {2016-06-01},
  journaltitle = {Science Translational Medicine},
  shortjournal = {Sci. Transl. Med.},
  volume = {8},
  number = {341},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  url = {https://stm.sciencemag.org/lookup/doi/10.1126/scitranslmed.aaf5027},
  urldate = {2020-09-11},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/HDKKJIR3/Goodman et al. - 2016 - What does research reproducibility mean.pdf}
}

@article{goodman2016a,
  title = {What {{Does Research Reproducibility Mean}}?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  date = {2016-06},
  journaltitle = {Science Translational Medicine},
  volume = {8},
  number = {341},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  langid = {english},
  keywords = {done}
}

@article{goodman2016b,
  title = {What {{Does Research Reproducibility Mean}}?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  date = {2016-06},
  journaltitle = {Science Translational Medicine},
  volume = {8},
  number = {341},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  langid = {english},
  keywords = {done}
}

@article{goodmanWhatDoesResearch2016,
  title = {What {{Does Research Reproducibility Mean}}?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  date = {2016-06},
  journaltitle = {Science Translational Medicine},
  volume = {8},
  number = {341},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  langid = {english},
  keywords = {done}
}

@article{goodmanWhatDoesResearch2016a,
  title = {What {{Does Research Reproducibility Mean}}?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  date = {2016-06},
  journaltitle = {Science Translational Medicine},
  volume = {8},
  number = {341},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  langid = {english},
  keywords = {done}
}

@book{greene2003,
  title = {Econometric Analysis},
  author = {Greene, WH},
  date = {2003},
  publisher = {{Prentice Hall}},
  location = {{New Jersey}},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@book{grolemund,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  url = {https://r4ds.had.co.nz/},
  urldate = {2020-08-19},
  abstract = {This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
  file = {/Users/agwd/Zotero/storage/ZVWKI7ZV/r4ds.had.co.nz.html}
}

@book{grolemunda,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  shorttitle = {R {{Markdown}}},
  author = {Grolemund, J. J. Allaire, Garrett, Yihui Xie},
  url = {https://bookdown.org/yihui/rmarkdown/},
  urldate = {2019-04-25},
  abstract = {The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages.},
  file = {/Users/agwd/Zotero/storage/XKXMVKYP/rmarkdown.html}
}

@book{grolemundb,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  abstract = {This book will teach you how to do data science with R: You'll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you'll learn how to clean data and draw plots— and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You'll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You'll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.}
}

@book{grolemundc,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  abstract = {This book will teach you how to do data science with R: You'll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you'll learn how to clean data and draw plots— and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You'll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You'll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.}
}

@book{grolemundDataScience,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  abstract = {This book will teach you how to do data science with R: You'll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you'll learn how to clean data and draw plots— and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You'll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You'll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.}
}

@book{grolemundDataSciencea,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  abstract = {This book will teach you how to do data science with R: You'll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you'll learn how to clean data and draw plots— and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You'll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You'll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.}
}

@manual{grosjean2018,
  type = {manual},
  title = {Pastecs: {{Package}} for Analysis of Space-Time Ecological Series},
  author = {Grosjean, Philippe and Ibanez, Frederic},
  date = {2018},
  url = {https://CRAN.R-project.org/package=pastecs}
}

@book{gruber,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{grubera,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberb,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberc,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberDaringFireballMarkdown,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberDaringFireballMarkdowna,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberDaringFireballMarkdownb,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@book{gruberDaringFireballMarkdownc,
  title = {Daring {{Fireball}}: {{Markdown}}},
  author = {Gruber, John and Swartz, Aron},
  keywords = {done}
}

@article{grytten2016,
  title = {Norske Børshandlede Produkter: En Analyse Av {{ETN}} Og {{ETF}}},
  shorttitle = {Norske Børshandlede Produkter},
  author = {Grytten, Linn},
  date = {2016},
  url = {https://core.ac.uk/display/52138349},
  urldate = {2020-05-07},
  abstract = {Masteroppgave i bedriftsøkonomi - Nord universitet, 201},
  langid = {british},
  file = {/Users/agwd/Zotero/storage/E9JCJZIK/Grytten - 2016 - Norske børshandlede produkter en analyse av ETN o.pdf;/Users/agwd/Zotero/storage/DNU6N5KX/52138349.html}
}

@article{halleckvega2015,
  title = {{{THE SLX MODEL}}},
  author = {Halleck Vega, Solmaria and Elhorst, J. Paul},
  date = {2015},
  journaltitle = {Journal of Regional Science},
  volume = {55},
  number = {3},
  pages = {339--363},
  doi = {10.1111/jors.12188},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jors.12188},
  abstract = {ABSTRACT We provide a comprehensive overview of the strengths and weaknesses of different spatial econometric model specifications in terms of spillover effects. Based on this overview, we advocate taking the SLX model as point of departure in case a well-founded theory indicating which model is most appropriate is lacking. In contrast to other spatial econometric models, the SLX model also allows for the spatial weights matrix W to be parameterized and the application of standard econometric techniques to test for endogenous explanatory variables. This starkly contrasts commonly used spatial econometric specification strategies and is a complement to the critique of spatial econometrics raised in a special theme issue of the Journal of Regional Science (Volume 52, Issue 2). To illustrate the pitfalls of the standard spatial econometrics approach and the benefits of our proposed alternative approach in an empirical setting, the Baltagi and Li (2004) cigarette demand model is estimated.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jors.12188}
}

@article{hamilton1982,
  title = {Wasteful Commuting},
  author = {Hamilton, BW},
  date = {1982},
  journaltitle = {Journal of Political Economy},
  volume = {90},
  pages = {1497--1504},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{handy1997,
  title = {Measuring Accessibility: An Exploration of Issues and Alternatives},
  author = {Handy, SL and Niemeier, DA},
  date = {1997},
  journaltitle = {Environment and Planning A},
  volume = {29},
  pages = {1175--1194},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{hansen1959,
  title = {How Accessibility Shapes Land Use},
  author = {Hansen, WG},
  date = {1959},
  journaltitle = {Journal of the American Institute of Planners},
  volume = {25},
  pages = {73--76},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@manual{harrelljr2020,
  type = {manual},
  title = {Hmisc: {{Harrell}} Miscellaneous},
  author = {Harrell Jr, Frank E and Dupont, with contributions from Charles and {others.}, many},
  date = {2020},
  url = {https://CRAN.R-project.org/package=Hmisc}
}

@book{hastie1990,
  title = {Generalized Additive Models},
  author = {Hastie, T and Tibshirani, RJ},
  date = {1990},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{healy2019,
  title = {Data {{Visualization}} ({{A Practical Introduction}})},
  author = {Healy, Kieran},
  date = {2019},
  edition = {1. ed.},
  publisher = {{Princeton University Press}},
  url = {https://socviz.co/index.html},
  isbn = {978-0-691-18162-2},
  pagetotal = {296}
}

@article{heikkila1989,
  title = {What Happened to the {{CBD}}-Distance Gradient?: Land Values in a Polycentric City},
  author = {Heikkila, E and Gordon, P and Kim, JI and Peiser, RB and Richardson, HW},
  date = {1989},
  journaltitle = {Environment and Planning A},
  volume = {21},
  pages = {221--232},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{holt1996,
  title = {Aggregation and Ecological Effects in Geographically Based Data},
  author = {Holt, D and Steel, D and Tranmer, M and Wrigley, N},
  date = {1996},
  journaltitle = {Geographical Analysis},
  volume = {28},
  pages = {244--261},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{hoogstra2017,
  title = {Do Jobs Follow People or People Follow Jobs? {{A}} Meta-Analysis of {{Carlino}}–{{Mills}} Studies},
  author = {Hoogstra, Gerke J. and van Dijk, Jouke and Florax, Raymond J.G.M.},
  options = {useprefix=true},
  date = {2017-10-02},
  journaltitle = {Spatial Economic Analysis},
  volume = {12},
  number = {4},
  pages = {357--378},
  publisher = {{Routledge}},
  issn = {1742-1772},
  doi = {10.1080/17421772.2017.1340663},
  abstract = {Do jobs follow people or people follow jobs? A meta-analysis of Carlino–Mills studies. Spatial Economic Analysis. This study examines the classic question as to whether ‘jobs follow people’ or ‘people follow jobs’ by performing a meta-analysis of 321 results from 64 Carlino–Mills studies. It is found that the results are highly divergent, but that more results point towards ‘jobs following people’ than towards ‘people following jobs’. When it comes to the reasons for the variation in results, we find that the results are mostly shaped by the geographical location, spatial resolution, and population and employment characteristics present in the data, as well as by the model’s specification, its functional form and the spatial weight matrix specification.},
  langid = {english},
  keywords = {adjustment model,Carlino–Mills model,jobs–people causality,meta-analysis,Population–employment interaction,simultaneous equations}
}

@article{hughes1992,
  title = {Traffic Externalities and Single-Family House Prices},
  author = {Hughes, JWT and Sirmans, CF},
  date = {1992},
  journaltitle = {Journal of Regional Science},
  volume = {32},
  number = {4},
  pages = {487--500},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{hull2012,
  title = {Options, Futures, and Other Derivatives},
  author = {Hull, John},
  date = {2012},
  edition = {8th ed., global ed.},
  publisher = {Pearson},
  location = {Boston, Mass},
  isbn = {9780273759072},
  langid = {english},
  keywords = {aksjer,børsspekulasjon,Capital market,derivater,Derivater,Economic analysis,Financing,futures,investering,investeringer,Investeringer,investeringsteori,Investment,Kapitalmarked,Økonomi,opsjoner,Opsjoner,opsjonshandel,Opsjonshandel : Spekulasjon,opsjonsmarkeder,Opsjonsmarkeder,porteføjeteori,Terminmarked,verdipapirer,Verdipapirer,Verdipapirer : Investering : Bank- og pengevesen,verdipapirhandel}
}

@book{hull2014,
  title = {Students Solutions Manual \& Study Guide for {{Fundamentals}} of Futures and Options Markets, Eighth Edition},
  author = {Hull, John and Hull, John},
  date = {2014},
  isbn = {978-1-292-04162-9},
  langid = {english},
  annotation = {OCLC: 865160008}
}

@book{hull2015,
  title = {Risk Management and Financial Institutions},
  author = {Hull, John},
  date = {2015},
  series = {Wiley Finance Series},
  edition = {Fourth edition},
  publisher = {{Wiley}},
  location = {{Hoboken, New Jersey}},
  abstract = {Business snapshots -- Preface -- Introduction -- Financial institutions and their trading -- Banks -- Insurance companies and pension plans -- Mutual funds and hedge funds -- Appendix a: compounding frequencies and interest rates -- Appendix b: zero rates, forward rates, and zero-coupon yield curves -- Appendix c: valuing forward and futures contracts -- Appendix d: valuing swaps -- Appendix e: valuing european options -- Appendix f: valuing american options -- Appendix g: taylor series expansions -- Appendix h: eigenvectors and eigenvalues -- Appendix i: principal components analysis -- Appendix j: manipulation of credit transition matrices -- Appendix k: valuation of credit default swaps -- Appendix l: synthetic cdos and their valuation -- Answers to questions and problems -- Glossary of terms -- Derivagem software},
  isbn = {978-1-118-95595-6 978-1-118-95594-9 978-1-118-95596-3},
  langid = {english},
  pagetotal = {714},
  annotation = {OCLC: 908622504},
  file = {/Users/agwd/Zotero/storage/2CM4NSRB/Hull - 2015 - Risk management and financial institutions.pdf}
}

@book{hull2018,
  title = {Options, Futures, and Other Derivatives},
  author = {Hull, John},
  date = {2018},
  edition = {9th ed., global ed.},
  publisher = {{Pearson}},
  location = {{Harlow}},
  isbn = {978-1-292-21289-0},
  langid = {english},
  pagetotal = {891},
  keywords = {aksjer,børsspekulasjon,derivater,futures,investering,investeringer,investeringsteori,økonomi,opsjoner,opsjonshandel,opsjonsmarkeder,porteføljeteori,verdipapirer,verdipapirhandel}
}

@inproceedings{ihaka1996,
  title = {Gentleman {{R}}: {{R}}: {{A}} Language for Data Analysis and Graphics},
  author = {Ihaka, Ross},
  date = {1996}
}

@article{ioannidis2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08-30},
  journaltitle = {PLOS Medicine},
  shortjournal = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124},
  urldate = {2020-09-10},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {Cancer risk factors,Finance,Genetic epidemiology,Genetics of disease,Metaanalysis,Randomized controlled trials,Research design,Schizophrenia},
  file = {/Users/agwd/Zotero/storage/9HIDLC24/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf;/Users/agwd/Zotero/storage/I2MHG9U3/article.html}
}

@article{ioannidis2005a,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08},
  journaltitle = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {done}
}

@article{ioannidis2005b,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08},
  journaltitle = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {done}
}

@article{ioannidisWhyMostPublished2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08},
  journaltitle = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {done}
}

@article{ioannidisWhyMostPublished2005a,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  date = {2005-08},
  journaltitle = {PLOS Medicine},
  volume = {2},
  number = {8},
  pages = {e124},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  langid = {english},
  keywords = {done}
}

@article{iyengar1988,
  title = {Selection Models and the File Drawer Problem},
  author = {Iyengar, Satish and Greenhouse, Joel B.},
  date = {1988},
  journaltitle = {Statistical Science},
  volume = {3},
  number = {1},
  eprint = {2245925},
  eprinttype = {jstor},
  pages = {109--117},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {08834237},
  abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.}
}

@article{iyengar1988a,
  title = {Selection {{Models}} and the {{File Drawer Problem}}},
  author = {Iyengar, Satish and Greenhouse, Joel B.},
  date = {1988},
  journaltitle = {Statistical Science},
  volume = {3},
  number = {1},
  pages = {109--117},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {08834237},
  abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.},
  keywords = {done}
}

@article{iyengar1988b,
  title = {Selection {{Models}} and the {{File Drawer Problem}}},
  author = {Iyengar, Satish and Greenhouse, Joel B.},
  date = {1988},
  journaltitle = {Statistical Science},
  volume = {3},
  number = {1},
  pages = {109--117},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {08834237},
  abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.},
  keywords = {done}
}

@article{iyengarSelectionModelsFile1988,
  title = {Selection {{Models}} and the {{File Drawer Problem}}},
  author = {Iyengar, Satish and Greenhouse, Joel B.},
  date = {1988},
  journaltitle = {Statistical Science},
  volume = {3},
  number = {1},
  pages = {109--117},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {08834237},
  abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.},
  keywords = {done}
}

@article{iyengarSelectionModelsFile1988a,
  title = {Selection {{Models}} and the {{File Drawer Problem}}},
  author = {Iyengar, Satish and Greenhouse, Joel B.},
  date = {1988},
  journaltitle = {Statistical Science},
  volume = {3},
  number = {1},
  pages = {109--117},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {08834237},
  abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.},
  keywords = {done}
}

@article{jackson1979,
  title = {Intraurban Variation in the Price of Housing},
  author = {Jackson, JR},
  date = {1979},
  journaltitle = {Journal of Urban Economics},
  volume = {6},
  pages = {464--479},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{jasny2011,
  title = {Again, and Again, and Again},
  author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
  date = {2011},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {https://science.sciencemag.org/content/334/6060/1225.full.pdf},
  pages = {1225--1225},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.334.6060.1225},
  url = {https://science.sciencemag.org/content/334/6060/1225}
}

@article{jasny2011a,
  title = {Again, and {{Again}}, and {{Again}}},
  author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
  date = {2011},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  pages = {1225--1225},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.334.6060.1225},
  keywords = {done}
}

@article{jasny2011b,
  title = {Again, and {{Again}}, and {{Again}}},
  author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
  date = {2011},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  pages = {1225--1225},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.334.6060.1225},
  keywords = {done}
}

@article{jasnyAgainAgainAgain2011,
  title = {Again, and {{Again}}, and {{Again}}},
  author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
  date = {2011},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  pages = {1225--1225},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.334.6060.1225},
  keywords = {done}
}

@article{jasnyAgainAgainAgain2011a,
  title = {Again, and {{Again}}, and {{Again}}},
  author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
  date = {2011},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  pages = {1225--1225},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.334.6060.1225},
  keywords = {done}
}

@article{judge2004,
  title = {The {{Effect}} of {{Physical Height}} on {{Workplace Success}} and {{Income}}: {{Preliminary Test}} of a {{Theoretical Model}}.},
  shorttitle = {The {{Effect}} of {{Physical Height}} on {{Workplace Success}} and {{Income}}},
  author = {Judge, Timothy A. and Cable, Daniel M.},
  date = {2004},
  journaltitle = {Journal of Applied Psychology},
  shortjournal = {Journal of Applied Psychology},
  volume = {89},
  number = {3},
  pages = {428--441},
  issn = {1939-1854, 0021-9010},
  doi = {10.1037/0021-9010.89.3.428},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0021-9010.89.3.428},
  urldate = {2020-08-28},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/S39RZTSJ/Judge og Cable - 2004 - The Effect of Physical Height on Workplace Success.pdf}
}

@article{juhl2021,
  title = {The {{Wald Test}} of {{Common Factors}} in {{Spatial Model Specification Search Strategies}}},
  author = {Juhl, Sebastian},
  date = {2021-04},
  journaltitle = {Political Analysis},
  volume = {29},
  number = {2},
  pages = {193--211},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2020.23},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/wald-test-of-common-factors-in-spatial-model-specification-search-strategies/20B76FF1F7D5D3167B370AECAF9ADD4D},
  urldate = {2021-06-20},
  abstract = {Distinguishing substantively meaningful spillover effects from correlated residuals is of great importance in cross-sectional studies. Both forms of spatial dependence not only hold different implications for the choice of an unbiased estimator but also for the validity of inferences. To guide model specification, different empirical strategies involve the estimation of an unrestricted spatial Durbin model and subsequently use the Wald test to scrutinize the nonlinear restriction of common factors implied by pure error dependence. However, the Wald test’s sensitivity to algebraically equivalent formulations of the null hypothesis receives scant attention in the context of cross-sectional analyses. This article shows analytically that the noninvariance of the Wald test to such reparameterizations stems from the application of a Taylor series expansion to approximate the restriction’s sampling distribution. While asymptotically valid, Monte Carlo simulations reveal that alternative formulations of the common factor restriction frequently produce conflicting conclusions in finite samples. An empirical example illustrates the substantive implications of this problem. Consequently, researchers should either base inferences on bootstrap critical values for the Wald statistic or use the likelihood ratio test which is invariant to such reparameterizations when deciding on the model specification that adequately reflects the spatial process generating the data.},
  langid = {english},
  keywords = {common factors,spatial econometrics,spillover effects,Wald test},
  file = {/Users/agwd/Zotero/storage/KCENMGLI/Juhl - 2021 - The Wald Test of Common Factors in Spatial Model S.pdf}
}

@article{juhl2021a,
  title = {The {{Wald Test}} of {{Common Factors}} in {{Spatial Model Specification Search Strategies}}},
  author = {Juhl, Sebastian},
  date = {2021-04},
  journaltitle = {Political Analysis},
  volume = {29},
  number = {2},
  pages = {193--211},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2020.23},
  url = {https://www.cambridge.org/core/journals/political-analysis/article/wald-test-of-common-factors-in-spatial-model-specification-search-strategies/20B76FF1F7D5D3167B370AECAF9ADD4D},
  urldate = {2021-06-20},
  abstract = {Distinguishing substantively meaningful spillover effects from correlated residuals is of great importance in cross-sectional studies. Both forms of spatial dependence not only hold different implications for the choice of an unbiased estimator but also for the validity of inferences. To guide model specification, different empirical strategies involve the estimation of an unrestricted spatial Durbin model and subsequently use the Wald test to scrutinize the nonlinear restriction of common factors implied by pure error dependence. However, the Wald test’s sensitivity to algebraically equivalent formulations of the null hypothesis receives scant attention in the context of cross-sectional analyses. This article shows analytically that the noninvariance of the Wald test to such reparameterizations stems from the application of a Taylor series expansion to approximate the restriction’s sampling distribution. While asymptotically valid, Monte Carlo simulations reveal that alternative formulations of the common factor restriction frequently produce conflicting conclusions in finite samples. An empirical example illustrates the substantive implications of this problem. Consequently, researchers should either base inferences on bootstrap critical values for the Wald statistic or use the likelihood ratio test which is invariant to such reparameterizations when deciding on the model specification that adequately reflects the spatial process generating the data.},
  langid = {english},
  keywords = {common factors,spatial econometrics,spillover effects,Wald test}
}

@article{kanbur2019,
  title = {Inequality {{Indices}} as {{Tests}} of {{Fairness}}},
  author = {Kanbur, Ravi and Snell, Andy},
  date = {2019-07-01},
  journaltitle = {Economic Journal},
  shortjournal = {Econ. J.},
  volume = {129},
  number = {621},
  pages = {2216--2239},
  issn = {0013-0133},
  doi = {10.1111/ecoj.12637},
  abstract = {Inequality indices are traditionally interpreted as measures of deviations from equality. This article interprets them instead as statistical tests for a null of fairness within well-defined income generating processes. We find that the likelihood ratio (LR) test for fairness versus unfairness within two such processes are proportional to Theil's first and second inequality indices respectively. The LR values may be used either as a test statistic or to approximate a Bayes factor that measures the posterior probabilities of the fair version of the processes over that of the unfair. We also apply this perspective to measurement of inequality of opportunity.},
  langid = {english},
  keywords = {equality,opportunity theory,risk,welfare},
  annotation = {WOS:000477674000011},
  file = {/Users/agwd/Zotero/storage/EWVMNKMZ/Kanbur and Snell - 2019 - Inequality Indices as Tests of Fairness.pdf}
}

@article{kirby2009,
  title = {Changes in Commuting to Work Times over the 1990 to 2000 Period},
  author = {Kirby, DK and LeSage, J},
  date = {2009},
  journaltitle = {Regional Science and Urban Economics},
  volume = {39},
  pages = {460--471},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{klein2018,
  title = {Many Labs 2: {{Investigating}} Variation in Replicability across Samples and Settings},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Reginald B. Adams, Jr. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Rosa, Anna Dalla and Davis, William E. and de Bruijn, Maaike and Schutter, Leander De and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, Åse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Neil A. Lewis, Jr. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Međedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Nichols, Austin Lee and Ocampo, Aaron and O’Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van ’t Veer, Anna Elisabeth and Echeverría, Alejandro Vásquez- and Vaughn, Leigh Ann and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {4},
  eprint = {https://doi.org/10.1177/2515245918810225},
  pages = {443--490},
  doi = {10.1177/2515245918810225},
  url = {https://doi.org/10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p ¡ .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p ¡ .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen’s ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (¡ 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.}
}

@article{klein2018a,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability}} across {{Samples}} and {{Settings}}},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Reginald B. Adams, Jr. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Rosa, Anna Dalla and Davis, William E. and de Bruijn, Maaike and Schutter, Leander De and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, \textbackslash AAse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Neil A. Lewis, Jr. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me\textbackslash djedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Nichols, Austin Lee and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van 't Veer, Anna Elisabeth and Echeverría, Alejandro Vásquez- and Vaughn, Leigh Ann and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {4},
  pages = {443--490},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p ¡ .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p ¡ .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (¡ 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  keywords = {done}
}

@article{klein2018b,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability}} across {{Samples}} and {{Settings}}},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Reginald B. Adams, Jr. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Rosa, Anna Dalla and Davis, William E. and de Bruijn, Maaike and Schutter, Leander De and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, \textbackslash AAse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Neil A. Lewis, Jr. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me\textbackslash djedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Nichols, Austin Lee and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van 't Veer, Anna Elisabeth and Echeverría, Alejandro Vásquez- and Vaughn, Leigh Ann and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {4},
  pages = {443--490},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p ¡ .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p ¡ .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (¡ 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  keywords = {done}
}

@article{kleinManyLabsInvestigating2018,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability}} across {{Samples}} and {{Settings}}},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Reginald B. Adams, Jr. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Rosa, Anna Dalla and Davis, William E. and de Bruijn, Maaike and Schutter, Leander De and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, \textbackslash AAse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Neil A. Lewis, Jr. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me\textbackslash djedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Nichols, Austin Lee and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van 't Veer, Anna Elisabeth and Echeverría, Alejandro Vásquez- and Vaughn, Leigh Ann and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {4},
  pages = {443--490},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p ¡ .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p ¡ .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (¡ 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  keywords = {done}
}

@article{kleinManyLabsInvestigating2018a,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability}} across {{Samples}} and {{Settings}}},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Reginald B. Adams, Jr. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Rosa, Anna Dalla and Davis, William E. and de Bruijn, Maaike and Schutter, Leander De and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, \textbackslash AAse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Neil A. Lewis, Jr. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me\textbackslash djedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Nichols, Austin Lee and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van 't Veer, Anna Elisabeth and Echeverría, Alejandro Vásquez- and Vaughn, Leigh Ann and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {4},
  pages = {443--490},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p ¡ .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p ¡ .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (¡ 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  keywords = {done}
}

@article{knuth1984,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  date = {1984-01},
  journaltitle = {The Computer Journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  keywords = {done}
}

@article{knuth1984a,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  date = {1984-01},
  journaltitle = {The Computer Journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  keywords = {done}
}

@book{knuth1986,
  title = {The {{TeXbook}}},
  author = {Knuth, D.E.},
  date = {1986},
  series = {Computers \& Typesetting},
  publisher = {{Addison-Wesley}},
  url = {https://books.google.no/books?id=zqgQAQAAMAAJ},
  isbn = {978-0-201-13447-6},
  lccn = {85030845}
}

@book{knuth1986a,
  title = {The {{TeXbook}}},
  author = {Knuth, D.E.},
  date = {1986},
  series = {Computers \& {{Typesetting}}},
  publisher = {{Addison-Wesley}},
  isbn = {978-0-201-13447-6},
  lccn = {85030845},
  keywords = {done}
}

@book{knuth1986b,
  title = {The {{TeXbook}}},
  author = {Knuth, D.E.},
  date = {1986},
  series = {Computers \& {{Typesetting}}},
  publisher = {{Addison-Wesley}},
  isbn = {978-0-201-13447-6},
  lccn = {85030845},
  keywords = {done}
}

@book{knuth1992,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-06-01},
  edition = {1st edition},
  publisher = {{Center for the Study of Language and Inf}},
  location = {{Stanford, Calif.}},
  abstract = {This anthology of essays from Donald Knuth, "the father of computer science," and~the inventor of literate programming includes early essays on related topics such as structured programming, as well as The Computer Journal article that launched literate programming itself. Many examples are given, including excerpts from the programs for TeX and METAFONT. The final essay is an example of CWEB, a system for literate programming in C and related languages.This volume is first in a series of Knuth's collected works.},
  isbn = {978-0-937073-80-3},
  langid = {english},
  pagetotal = {384}
}

@book{knuth1992a,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-03-30},
  eprint = {vovpQgAACAAJ},
  eprinttype = {googlebooks},
  publisher = {{Cambridge University Press}},
  abstract = {Literate programming is a programming methodology that combines a programming language with a documentation language, making programs more robust, more portable, and more easily maintained than programs written only in a high-level language. Computer programmers already know both kinds of languages; they need only learn a few conventions about alternating between languages to create programs that are works of literature. A literate programmer is an essayist who writes programs for humans to understand, instead of primarily writing instructions for machines to follow. When programs are written in the recommended style they can be transformed into documents by a document compiler and into efficient code by an algebraic compiler. This anthology of essays from the inventor of literate programming includes Knuth's early papers on related topics such as structured programming, as well as the Computer Journal article that launched literate programming itself.},
  isbn = {978-0-937073-81-0},
  langid = {english},
  pagetotal = {384},
  keywords = {Computers / Social Aspects}
}

@book{knuth1992b,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-03},
  publisher = {{Cambridge University Press}},
  abstract = {Literate programming is a programming methodology that combines a programming language with a documentation language, making programs more robust, more portable, and more easily maintained than programs written only in a high-level language. Computer programmers already know both kinds of languages; they need only learn a few conventions about alternating between languages to create programs that are works of literature. A literate programmer is an essayist who writes programs for humans to understand, instead of primarily writing instructions for machines to follow. When programs are written in the recommended style they can be transformed into documents by a document compiler and into efficient code by an algebraic compiler. This anthology of essays from the inventor of literate programming includes Knuth's early papers on related topics such as structured programming, as well as the Computer Journal article that launched literate programming itself.},
  isbn = {978-0-937073-81-0},
  langid = {english},
  keywords = {done}
}

@book{knuth1992c,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-03},
  publisher = {{Cambridge University Press}},
  abstract = {Literate programming is a programming methodology that combines a programming language with a documentation language, making programs more robust, more portable, and more easily maintained than programs written only in a high-level language. Computer programmers already know both kinds of languages; they need only learn a few conventions about alternating between languages to create programs that are works of literature. A literate programmer is an essayist who writes programs for humans to understand, instead of primarily writing instructions for machines to follow. When programs are written in the recommended style they can be transformed into documents by a document compiler and into efficient code by an algebraic compiler. This anthology of essays from the inventor of literate programming includes Knuth's early papers on related topics such as structured programming, as well as the Computer Journal article that launched literate programming itself.},
  isbn = {978-0-937073-81-0},
  langid = {english},
  keywords = {done}
}

@article{knuthLiterateProgramming1984,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  date = {1984-01},
  journaltitle = {The Computer Journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  keywords = {done}
}

@article{knuthLiterateProgramming1984a,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  date = {1984-01},
  journaltitle = {The Computer Journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  keywords = {done}
}

@book{knuthLiterateProgramming1992,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-03},
  publisher = {{Cambridge University Press}},
  abstract = {Literate programming is a programming methodology that combines a programming language with a documentation language, making programs more robust, more portable, and more easily maintained than programs written only in a high-level language. Computer programmers already know both kinds of languages; they need only learn a few conventions about alternating between languages to create programs that are works of literature. A literate programmer is an essayist who writes programs for humans to understand, instead of primarily writing instructions for machines to follow. When programs are written in the recommended style they can be transformed into documents by a document compiler and into efficient code by an algebraic compiler. This anthology of essays from the inventor of literate programming includes Knuth's early papers on related topics such as structured programming, as well as the Computer Journal article that launched literate programming itself.},
  isbn = {978-0-937073-81-0},
  langid = {english},
  keywords = {done}
}

@book{knuthLiterateProgramming1992a,
  title = {Literate {{Programming}}},
  author = {Knuth, Donald E.},
  date = {1992-03},
  publisher = {{Cambridge University Press}},
  abstract = {Literate programming is a programming methodology that combines a programming language with a documentation language, making programs more robust, more portable, and more easily maintained than programs written only in a high-level language. Computer programmers already know both kinds of languages; they need only learn a few conventions about alternating between languages to create programs that are works of literature. A literate programmer is an essayist who writes programs for humans to understand, instead of primarily writing instructions for machines to follow. When programs are written in the recommended style they can be transformed into documents by a document compiler and into efficient code by an algebraic compiler. This anthology of essays from the inventor of literate programming includes Knuth's early papers on related topics such as structured programming, as well as the Computer Journal article that launched literate programming itself.},
  isbn = {978-0-937073-81-0},
  langid = {english},
  keywords = {done}
}

@book{knuthTeXbook1986,
  title = {The {{TeXbook}}},
  author = {Knuth, D.E.},
  date = {1986},
  series = {Computers \& {{Typesetting}}},
  publisher = {{Addison-Wesley}},
  isbn = {978-0-201-13447-6},
  lccn = {85030845},
  keywords = {done}
}

@book{knuthTeXbook1986a,
  title = {The {{TeXbook}}},
  author = {Knuth, D.E.},
  date = {1986},
  series = {Computers \& {{Typesetting}}},
  publisher = {{Addison-Wesley}},
  isbn = {978-0-201-13447-6},
  lccn = {85030845},
  keywords = {done}
}

@online{kommentator,
  title = {Europas sikkerhet er i spill. USA kan havne på et sidespor, og hva skjer i Tyskland? | Frank Rossavik},
  shorttitle = {Europas sikkerhet er i spill. USA kan havne på et sidespor, og hva skjer i Tyskland?},
  author = {Kommentator, Frank Rossavik},
  url = {https://www.aftenposten.no/article/ap-6jqabW.html},
  urldate = {2019-04-10},
  abstract = {NATO trygger ikke freden.},
  langid = {norsk},
  organization = {{Aftenposten}},
  file = {/Users/agwd/Zotero/storage/YUEQ5WLH/Europas-sikkerhet-er-i-spill-USA-kan-havne-pa-et-sidespor_-og-hva-skjer-i-Tyskland--Frank-Rossa.html}
}

@online{kunnskapsdepartementet2018,
  type = {NOU},
  title = {NOU 2018: 15},
  shorttitle = {NOU 2018},
  author = {Kunnskapsdepartementet},
  date = {2018-12-10},
  url = {https://www.regjeringen.no/no/dokumenter/nou-2018-15/id2621801/},
  urldate = {2019-04-10},
  abstract = {Ragnhild Lied leder et utvalg som ble nedsatt av Kunnskapsdepartementet 1. september 2017. Liedutvalget har med dette overlevert den første av to utredninger.   10. desember 2018 overleverte utvalget utredningen Kvalifisert, forberedt og motivert. Et k...},
  langid = {norwegian},
  organization = {{Regjeringen.no}},
  file = {/Users/agwd/Zotero/storage/PV4AF6S5/id2621801.html}
}

@article{kwan2013,
  title = {Recent Advances in Accessibility Research: Representation, Methodology, and Applications},
  author = {Kwan, M-P and Murray, A T and O'Kelly, M E and Tiefelsdorf, M},
  date = {2013},
  journaltitle = {Journal of Geographical Systems},
  volume = {5},
  number = {1},
  pages = {129--138},
  date-added = {2020-01-09 14:57:14 +0100},
  date-modified = {2020-01-09 15:01:16 +0100},
  keywords = {ocp022019_REGION_template}
}

@article{lacombe2015,
  title = {Using Bayesian posterior model probabilities to identify omitted variables in spatial regression models},
  author = {Lacombe, Donald J. and LeSage, James P.},
  date = {2015},
  journaltitle = {Papers in Regional Science},
  volume = {94},
  number = {2},
  pages = {365--383},
  issn = {1435-5957},
  doi = {10.1111/pirs.12070},
  url = {https://rsaiconnect.onlinelibrary.wiley.com/doi/abs/10.1111/pirs.12070},
  urldate = {2021-06-20},
  abstract = {LeSage and Pace (2009) consider the impact of omitted variables in the face of spatial dependence in the disturbance process of a linear regression relationship and show that this can lead to a spatial Durbin model. Monte Carlo experiments and Bayesian model comparison methods are used to distinguish between spatial error and Durbin model specifications that arise with varying levels of correlation between included and omitted variables. The Monte Carlo results suggest use of the common factor relationship developed in Burridge (1981) as a way to test for the presence of omitted variables bias influencing specific explanatory variables.},
  langid = {spanish},
  keywords = {Bayesian model comparison methods,C11,C31,Common factor relationship,global spatial spillovers},
  annotation = {\_eprint: https://rsaiconnect.onlinelibrary.wiley.com/doi/pdf/10.1111/pirs.12070},
  file = {/Users/agwd/Zotero/storage/CH9C9J7K/Lacombe og LeSage - 2015 - Using Bayesian posterior model probabilities to id.pdf;/Users/agwd/Zotero/storage/LTZEZYPV/pirs.html}
}

@article{lacombe2015a,
  title = {Using Bayesian posterior model probabilities to identify omitted variables in spatial regression models},
  author = {Lacombe, Donald J. and LeSage, James P.},
  date = {2015},
  journaltitle = {Papers in Regional Science},
  volume = {94},
  number = {2},
  pages = {365--383},
  issn = {1435-5957},
  doi = {10.1111/pirs.12070},
  url = {https://rsaiconnect.onlinelibrary.wiley.com/doi/abs/10.1111/pirs.12070},
  urldate = {2021-06-20},
  abstract = {LeSage and Pace (2009) consider the impact of omitted variables in the face of spatial dependence in the disturbance process of a linear regression relationship and show that this can lead to a spatial Durbin model. Monte Carlo experiments and Bayesian model comparison methods are used to distinguish between spatial error and Durbin model specifications that arise with varying levels of correlation between included and omitted variables. The Monte Carlo results suggest use of the common factor relationship developed in Burridge (1981) as a way to test for the presence of omitted variables bias influencing specific explanatory variables.},
  langid = {spanish},
  keywords = {Bayesian model comparison methods,C11,C31,Common factor relationship,global spatial spillovers},
  annotation = {\_eprint: https://rsaiconnect.onlinelibrary.wiley.com/doi/pdf/10.1111/pirs.12070},
  file = {/Users/agwd/Zotero/storage/GRPC63GZ/pirs.html}
}

@book{lamport1986,
  title = {{{LATEX}}: A Document Preparation System},
  shorttitle = {{{LATEX}}},
  author = {Lamport, Leslie},
  date = {1986},
  pages = {XIV, 242},
  publisher = {{Addison-Wesley}},
  location = {{Reading, Mass}},
  isbn = {978-0-201-15790-1},
  langid = {english},
  pagetotal = {xiv+242},
  keywords = {Databehandling; LATEX; Tekstbehandling; databehandling; desktop; publishing; typografi; trykking; informatikk; tex; latex; programvare; tekstbehandling; latex(program); satseteknikk; programmering; grafisk; grensesnitt; databasert; Typografi,Databehandling; Tekstbehandling; latex; tex; markeringsspråk; Typografi : Databehandling,LaTeX (Computer system); Computerized typesetting; Vitenskapelig publisering; LaTeX; Digital typografi; TeX; Tekstbehandling; Typografi; Informatikk; Programmering; Databehandling; Programvare; Typografi}
}

@book{lander2017,
  title = {R for {{Everyone}}: {{Advanced Analytics}} and {{Graphics}}},
  shorttitle = {R for {{Everyone}}},
  author = {Lander, Jared P.},
  date = {2017-06},
  edition = {2nd Edition},
  publisher = {{Addison-Wesley Professional}},
  location = {{Boston}},
  abstract = {Statistical Computation for Programmers, Scientists, Quants, Excel Users, and Other Professionals Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. Coverage includes Explore R, RStudio, and R packages Use R for math: variable types, vectors, calling functions, and more Exploit data structures, including data.frames, matrices, and lists Read many different types of data Create attractive, intuitive statistical graphics Write user-defined functions Control program flow with if, ifelse, and complex checks Improve program efficiency with group manipulations Combine and reshape multiple datasets Manipulate strings using R's facilities and regular expressions Create normal, binomial, and Poisson probability distributions Build linear, generalized linear, and nonlinear models Program basic statistics: mean, standard deviation, and t-tests Train machine learning models Assess the quality of models and variable selection Prevent overfitting and perform variable selection, using the Elastic Net and Bayesian methods Analyze univariate and multivariate time series data Group data via K-means and hierarchical clustering Prepare reports, slideshows, and web pages with knitr Display interactive data with RMarkdown and htmlwidgets Implement dashboards with Shiny Build reusable R packages with devtools and Rcpp Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available.},
  isbn = {978-0-13-454692-6},
  langid = {english}
}

@book{lander2017a,
  title = {R for {{Everyone}}: {{Advanced Analytics}} and {{Graphics}}},
  shorttitle = {R for {{Everyone}}},
  author = {Lander, Jared P.},
  date = {2017-06},
  edition = {2nd Edition},
  publisher = {{Addison-Wesley Professional}},
  location = {{Boston}},
  abstract = {Statistical Computation for Programmers, Scientists, Quants, Excel Users, and Other Professionals Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. Coverage includes Explore R, RStudio, and R packages Use R for math: variable types, vectors, calling functions, and more Exploit data structures, including data.frames, matrices, and lists Read many different types of data Create attractive, intuitive statistical graphics Write user-defined functions Control program flow with if, ifelse, and complex checks Improve program efficiency with group manipulations Combine and reshape multiple datasets Manipulate strings using R's facilities and regular expressions Create normal, binomial, and Poisson probability distributions Build linear, generalized linear, and nonlinear models Program basic statistics: mean, standard deviation, and t-tests Train machine learning models Assess the quality of models and variable selection Prevent overfitting and perform variable selection, using the Elastic Net and Bayesian methods Analyze univariate and multivariate time series data Group data via K-means and hierarchical clustering Prepare reports, slideshows, and web pages with knitr Display interactive data with RMarkdown and htmlwidgets Implement dashboards with Shiny Build reusable R packages with devtools and Rcpp Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available.},
  isbn = {978-0-13-454692-6},
  langid = {english}
}

@book{landerEveryoneAdvancedAnalytics2017,
  title = {R for {{Everyone}}: {{Advanced Analytics}} and {{Graphics}}},
  shorttitle = {R for {{Everyone}}},
  author = {Lander, Jared P.},
  date = {2017-06},
  edition = {2nd Edition},
  publisher = {{Addison-Wesley Professional}},
  location = {{Boston}},
  abstract = {Statistical Computation for Programmers, Scientists, Quants, Excel Users, and Other Professionals Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. Coverage includes Explore R, RStudio, and R packages Use R for math: variable types, vectors, calling functions, and more Exploit data structures, including data.frames, matrices, and lists Read many different types of data Create attractive, intuitive statistical graphics Write user-defined functions Control program flow with if, ifelse, and complex checks Improve program efficiency with group manipulations Combine and reshape multiple datasets Manipulate strings using R's facilities and regular expressions Create normal, binomial, and Poisson probability distributions Build linear, generalized linear, and nonlinear models Program basic statistics: mean, standard deviation, and t-tests Train machine learning models Assess the quality of models and variable selection Prevent overfitting and perform variable selection, using the Elastic Net and Bayesian methods Analyze univariate and multivariate time series data Group data via K-means and hierarchical clustering Prepare reports, slideshows, and web pages with knitr Display interactive data with RMarkdown and htmlwidgets Implement dashboards with Shiny Build reusable R packages with devtools and Rcpp Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available.},
  isbn = {978-0-13-454692-6},
  langid = {english}
}

@book{landerEveryoneAdvancedAnalytics2017a,
  title = {R for {{Everyone}}: {{Advanced Analytics}} and {{Graphics}}},
  shorttitle = {R for {{Everyone}}},
  author = {Lander, Jared P.},
  date = {2017-06},
  edition = {2nd Edition},
  publisher = {{Addison-Wesley Professional}},
  location = {{Boston}},
  abstract = {Statistical Computation for Programmers, Scientists, Quants, Excel Users, and Other Professionals Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. Coverage includes Explore R, RStudio, and R packages Use R for math: variable types, vectors, calling functions, and more Exploit data structures, including data.frames, matrices, and lists Read many different types of data Create attractive, intuitive statistical graphics Write user-defined functions Control program flow with if, ifelse, and complex checks Improve program efficiency with group manipulations Combine and reshape multiple datasets Manipulate strings using R's facilities and regular expressions Create normal, binomial, and Poisson probability distributions Build linear, generalized linear, and nonlinear models Program basic statistics: mean, standard deviation, and t-tests Train machine learning models Assess the quality of models and variable selection Prevent overfitting and perform variable selection, using the Elastic Net and Bayesian methods Analyze univariate and multivariate time series data Group data via K-means and hierarchical clustering Prepare reports, slideshows, and web pages with knitr Display interactive data with RMarkdown and htmlwidgets Implement dashboards with Shiny Build reusable R packages with devtools and Rcpp Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available.},
  isbn = {978-0-13-454692-6},
  langid = {english}
}

@incollection{leisch2002,
  title = {Sweave: {{Dynamic Generation}} of {{Statistical Reports Using Literate Data Analysis}}},
  shorttitle = {Sweave},
  booktitle = {Compstat},
  author = {Leisch, Friedrich},
  editor = {Härdle, Wolfgang and Rönz, Bernd},
  date = {2002},
  pages = {575--580},
  publisher = {{Physica-Verlag HD}},
  location = {{Heidelberg}},
  doi = {10.1007/978-3-642-57489-4_89},
  abstract = {Sweave combines typesetting with LATEX and data anlysis with S into integrated statistical documents. When run through R or Splus, all data analysis output (tables, graphs, . . . ) is created on the fly and inserted into a final LATEX document. Options control which parts of the original S code are shown to or hidden from the reader, respectively. Many S users are also LATEX users, hence no new software has to be learned. The report can be automatically updated if data or analysis change, which allows for truly reproducible research.},
  isbn = {978-3-7908-1517-7 978-3-642-57489-4},
  langid = {english},
  keywords = {done}
}

@incollection{leisch2002a,
  title = {Sweave: {{Dynamic Generation}} of {{Statistical Reports Using Literate Data Analysis}}},
  shorttitle = {Sweave},
  booktitle = {Compstat},
  author = {Leisch, Friedrich},
  editor = {Härdle, Wolfgang and Rönz, Bernd},
  date = {2002},
  pages = {575--580},
  publisher = {{Physica-Verlag HD}},
  location = {{Heidelberg}},
  doi = {10.1007/978-3-642-57489-4_89},
  abstract = {Sweave combines typesetting with LATEX and data anlysis with S into integrated statistical documents. When run through R or Splus, all data analysis output (tables, graphs, . . . ) is created on the fly and inserted into a final LATEX document. Options control which parts of the original S code are shown to or hidden from the reader, respectively. Many S users are also LATEX users, hence no new software has to be learned. The report can be automatically updated if data or analysis change, which allows for truly reproducible research.},
  isbn = {978-3-7908-1517-7 978-3-642-57489-4},
  langid = {english},
  keywords = {done}
}

@incollection{leischSweaveDynamicGeneration2002,
  title = {Sweave: {{Dynamic Generation}} of {{Statistical Reports Using Literate Data Analysis}}},
  shorttitle = {Sweave},
  booktitle = {Compstat},
  author = {Leisch, Friedrich},
  editor = {Härdle, Wolfgang and Rönz, Bernd},
  date = {2002},
  pages = {575--580},
  publisher = {{Physica-Verlag HD}},
  location = {{Heidelberg}},
  doi = {10.1007/978-3-642-57489-4_89},
  abstract = {Sweave combines typesetting with LATEX and data anlysis with S into integrated statistical documents. When run through R or Splus, all data analysis output (tables, graphs, . . . ) is created on the fly and inserted into a final LATEX document. Options control which parts of the original S code are shown to or hidden from the reader, respectively. Many S users are also LATEX users, hence no new software has to be learned. The report can be automatically updated if data or analysis change, which allows for truly reproducible research.},
  isbn = {978-3-7908-1517-7 978-3-642-57489-4},
  langid = {english},
  keywords = {done}
}

@incollection{leischSweaveDynamicGeneration2002a,
  title = {Sweave: {{Dynamic Generation}} of {{Statistical Reports Using Literate Data Analysis}}},
  shorttitle = {Sweave},
  booktitle = {Compstat},
  author = {Leisch, Friedrich},
  editor = {Härdle, Wolfgang and Rönz, Bernd},
  date = {2002},
  pages = {575--580},
  publisher = {{Physica-Verlag HD}},
  location = {{Heidelberg}},
  doi = {10.1007/978-3-642-57489-4_89},
  abstract = {Sweave combines typesetting with LATEX and data anlysis with S into integrated statistical documents. When run through R or Splus, all data analysis output (tables, graphs, . . . ) is created on the fly and inserted into a final LATEX document. Options control which parts of the original S code are shown to or hidden from the reader, respectively. Many S users are also LATEX users, hence no new software has to be learned. The report can be automatically updated if data or analysis change, which allows for truly reproducible research.},
  isbn = {978-3-7908-1517-7 978-3-642-57489-4},
  langid = {english},
  keywords = {done}
}

@article{lesage,
  title = {What Regional Scientists Need to Know about Spatial Econometrics},
  author = {LeSage, James P},
  pages = {31},
  abstract = {Regional scientists frequently work with regression relationships involving sample data that is spatial in nature. For example, hedonic house-price regressions relate selling prices of houses located at points in space to characteristics of the homes as well as neighborhood characteristics. Migration, commodity, and transportation flow models relate the size flows between origin and destination regions to the distance between origin and destination as well as characteristics of both origin and destination regions. Regional growth regressions relate growth rates of a region to past period ownand nearby-region resource inputs used in production.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/KPUI58MD/LeSage - What regional scientists need to know about spatia.pdf}
}

@article{lesage2008,
  title = {Spatial Growth Regressions: Model Specification, Estimation and Interpretation},
  author = {LeSage, J and Fischer, MM},
  date = {2008},
  journaltitle = {Spatial Economic Analysis},
  volume = {3},
  number = {3},
  publisher = {{Taylor and Francis Journals}},
  address = {275-304},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{lesage2009,
  title = {Introduction to Spatial Econometrics},
  author = {LeSage, J and Pace, RK},
  date = {2009},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton}},
  date-modified = {2012-02-28 12:24:08 +0000},
  pagetotal = {33-42, 114-115},
  keywords = {ocp022019_REGION_template}
}

@article{li1980,
  title = {Micro-Neighbourhood Externalities and Hedonic Prices},
  author = {Li, MM and Brown, HJ},
  date = {1980},
  journaltitle = {Land Economics},
  volume = {56},
  pages = {125--140},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@inreference{lovik2018,
  title = {pollenallergi},
  booktitle = {Store medisinske leksikon},
  author = {Løvik, Martinus},
  date = {2018-09-26T14:27:48.997+02:00},
  url = {http://sml.snl.no/pollenallergi},
  urldate = {2019-04-10},
  abstract = {Pollenallergi, eller pollinose, er allergi mot pollen, blomsterstøv frå planter og tre. Allergi er årsak til høysnue, som er ei form for allergisk rinokonjunktivitt, og kan også gje astma.Pollenallergi er mest vanleg i alderen frå fem til 40 år. Omlag ein person av fem i befolkninga har pollenallergi av ulik styrke. Åtte av ti astmatikarar har pollenallergi, omlag ein av fem pollenallergikarar har astma.Pollenallergikarar kan ha rett til forlenga tid på eksamen, med legeattest..},
  langid = {norwegian},
  keywords = {Allergologi},
  file = {/Users/agwd/Zotero/storage/AVC6IHDA/pollenallergi.html}
}

@article{lowndes2017,
  title = {Our Path to Better Science in Less Time Using Open Data Science Tools},
  author = {Lowndes, Julia S. Stewart and Best, Benjamin D. and Scarborough, Courtney and Afflerbach, Jamie C. and Frazier, Melanie R. and O’Hara, Casey C. and Jiang, Ning and Halpern, Benjamin S.},
  date = {2017-06},
  journaltitle = {Nature Ecology \& Evolution},
  volume = {1},
  number = {6},
  pages = {0160},
  issn = {2397-334X},
  doi = {10.1038/s41559-017-0160},
  url = {https://www.nature.com/articles/s41559-017-0160},
  urldate = {2019-04-26},
  abstract = {Reproducibility has long been a tenet of science but has been challenging to achieve—we learned this the hard way when our old approaches proved inadequate to efficiently reproduce our own work. Here we describe how several free software tools have fundamentally upgraded our approach to collaborative research, making our entire workflow more transparent and streamlined. By describing specific tools and how we incrementally began using them for the Ocean Health Index project, we hope to encourage others in the scientific community to do the same—so we can all produce better science in less time.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/55JYTX6Z/Lowndes et al. - 2017 - Our path to better science in less time using open.pdf;/Users/agwd/Zotero/storage/R7ACNCHA/s41559-017-0160.html}
}

@article{ma2006,
  title = {Excess Commuting: {{A}} Critical Review},
  author = {Ma, K and Banister, D},
  date = {2006},
  journaltitle = {Transport Reviews},
  volume = {26},
  pages = {749--767},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{markowetz2015,
  title = {Five Selfish Reasons to Work Reproducibly},
  author = {Markowetz, Florian},
  date = {2015-12},
  journaltitle = {Genome Biology},
  shortjournal = {Genome Biol},
  volume = {16},
  number = {1},
  pages = {274},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0850-7},
  urldate = {2020-09-11},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/RC383V7P/Markowetz - 2015 - Five selfish reasons to work reproducibly.pdf}
}

@article{markowetz2015a,
  title = {Five {{Selfish Reasons}} to {{Work Reproducibly}}},
  author = {Markowetz, Florian},
  date = {2015-12},
  journaltitle = {Genome Biology},
  volume = {16},
  number = {1},
  pages = {274},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  langid = {english}
}

@article{markowetz2015b,
  title = {Five {{Selfish Reasons}} to {{Work Reproducibly}}},
  author = {Markowetz, Florian},
  date = {2015-12},
  journaltitle = {Genome Biology},
  volume = {16},
  number = {1},
  pages = {274},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  langid = {english}
}

@article{markowetzFiveSelfishReasons2015,
  title = {Five {{Selfish Reasons}} to {{Work Reproducibly}}},
  author = {Markowetz, Florian},
  date = {2015-12},
  journaltitle = {Genome Biology},
  volume = {16},
  number = {1},
  pages = {274},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  langid = {english}
}

@article{markowetzFiveSelfishReasons2015a,
  title = {Five {{Selfish Reasons}} to {{Work Reproducibly}}},
  author = {Markowetz, Florian},
  date = {2015-12},
  journaltitle = {Genome Biology},
  volume = {16},
  number = {1},
  pages = {274},
  issn = {1474-760X},
  doi = {10.1186/s13059-015-0850-7},
  langid = {english}
}

@article{mccullough2008,
  title = {Do Economics Journal Archives Promote Replicable Research?},
  author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  date = {2008},
  journaltitle = {Canadian Journal of Economics/Revue canadienne d'économique},
  volume = {41},
  number = {4},
  pages = {1406--1420},
  issn = {1540-5982},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5982.2008.00509.x},
  urldate = {2020-08-19},
  abstract = {Abstract. All the long-standing archives at economics journals do not facilitate the reproduction of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive. Recently created archives at top journals should avoid the mistakes of their predecessors. We categorize reasons for archives' failures and identify successful policies.},
  langid = {english},
  keywords = {B40,C80},
  annotation = {\_eprint: https://www.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5982.2008.00509.x},
  file = {/Users/agwd/Zotero/storage/IG3UBBR6/McCullough et al. - 2008 - Do economics journal archives promote replicable r.pdf;/Users/agwd/Zotero/storage/8RVGH4TY/j.1540-5982.2008.00509.html}
}

@article{mccullough2008a,
  title = {Do {{Economics Journal Archives Promote Replicable Research}}?},
  author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  date = {2008},
  journaltitle = {Canadian Journal of Economics/Revue canadienne d'économique},
  volume = {41},
  number = {4},
  pages = {1406--1420},
  issn = {1540-5982},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  abstract = {Abstract. All the long-standing archives at economics journals do not facilitate the reproduction of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive. Recently created archives at top journals should avoid the mistakes of their predecessors. We categorize reasons for archives' failures and identify successful policies.},
  copyright = {© Canadian Economics Association},
  langid = {english},
  keywords = {done}
}

@article{mccullough2008b,
  title = {Do {{Economics Journal Archives Promote Replicable Research}}?},
  author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  date = {2008},
  journaltitle = {Canadian Journal of Economics/Revue canadienne d'économique},
  volume = {41},
  number = {4},
  pages = {1406--1420},
  issn = {1540-5982},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  abstract = {Abstract. All the long-standing archives at economics journals do not facilitate the reproduction of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive. Recently created archives at top journals should avoid the mistakes of their predecessors. We categorize reasons for archives' failures and identify successful policies.},
  copyright = {© Canadian Economics Association},
  langid = {english},
  keywords = {done}
}

@article{mcculloughEconomicsJournalArchives2008,
  title = {Do {{Economics Journal Archives Promote Replicable Research}}?},
  author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  date = {2008},
  journaltitle = {Canadian Journal of Economics/Revue canadienne d'économique},
  volume = {41},
  number = {4},
  pages = {1406--1420},
  issn = {1540-5982},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  abstract = {Abstract. All the long-standing archives at economics journals do not facilitate the reproduction of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive. Recently created archives at top journals should avoid the mistakes of their predecessors. We categorize reasons for archives' failures and identify successful policies.},
  copyright = {© Canadian Economics Association},
  langid = {english},
  keywords = {done}
}

@article{mcculloughEconomicsJournalArchives2008a,
  title = {Do {{Economics Journal Archives Promote Replicable Research}}?},
  author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  date = {2008},
  journaltitle = {Canadian Journal of Economics/Revue canadienne d'économique},
  volume = {41},
  number = {4},
  pages = {1406--1420},
  issn = {1540-5982},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  abstract = {Abstract. All the long-standing archives at economics journals do not facilitate the reproduction of published results. The data-only archives at Journal of Business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data. Results published in the FRB St. Louis Review can rarely be reproduced using the data+code in the journal archive. Recently created archives at top journals should avoid the mistakes of their predecessors. We categorize reasons for archives' failures and identify successful policies.},
  copyright = {© Canadian Economics Association},
  langid = {english},
  keywords = {done}
}

@article{mcmillen2003,
  title = {Spatial {{Autocorrelation}} or Model Misspecification?},
  author = {McMillen, DP},
  date = {2003},
  journaltitle = {International Regional Science Review},
  volume = {26},
  number = {2},
  pages = {208--217},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{mcnutt2014,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  eprint = {https://science.sciencemag.org/content/343/6168/229.full.pdf},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  url = {https://science.sciencemag.org/content/343/6168/229}
}

@article{mcnutt2014a,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  keywords = {done}
}

@article{mcnutt2014b,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  keywords = {done}
}

@article{McNutt229,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  eprint = {https://science.sciencemag.org/content/343/6168/229.full.pdf},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  url = {https://science.sciencemag.org/content/343/6168/229}
}

@article{mcnuttReproducibility2014,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  keywords = {done}
}

@article{mcnuttReproducibility2014a,
  title = {Reproducibility},
  author = {McNutt, Marcia},
  date = {2014},
  journaltitle = {Science},
  volume = {343},
  number = {6168},
  pages = {229--229},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.1250475},
  keywords = {done}
}

@report{mora2010,
  title = {Entropy-Based Segregation Indices},
  author = {Mora, Ricardo and Ruiz-Castillo, Javier},
  date = {2010-06},
  series = {{{UC3M Working}} Papers. {{Economics}}},
  number = {we1012},
  institution = {{Universidad Carlos III de Madrid. Departamento de Economía}},
  url = {https://ideas.repec.org/p/cte/werepe/we1012.html},
  urldate = {2019-09-13},
  abstract = {Recent research has shown that two entropy-based segregation indices possess an appealing mixture of basic and subsidiary but useful properties. It would appear that the only fundamental difference between the mutual information, or M index, and the Entropy, Information or H index, is that the second is a normalized version of the first. This paper introduces another normalized index in that famiy, the H* index that, contrary to what is often asserted in the literature, is the normalized entropy index that captures the notion of segregation as departures from evenness. More importantly, the paper shows that applied researchers may do better using the M index than using either H or H* in two dircunstances: (i) if they are interested in the decomposability of segregation measures for any partition of organizational units into larger clusters and of demographic groups into supergroups, and (ii) if they are interested in the invariance properties of segregation measures to changes in the marginal distributions by demographic groups and by organizational units},
  langid = {english},
  keywords = {Axiomatic properties},
  file = {/Users/agwd/Zotero/storage/7HZ3DE86/Mora and Ruiz-Castillo - 2010 - Entropy-based segregation indices.pdf;/Users/agwd/Zotero/storage/ULWPL6JT/we1012.html}
}

@book{muenchow,
  title = {Geocomputation with {{R}}},
  author = {Muenchow, Jakub Nowosad, Jannes, Robin Lovelace},
  url = {https://geocompr.robinlovelace.net/},
  urldate = {2021-05-12},
  abstract = {Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data.},
  file = {/Users/agwd/Zotero/storage/TWZICCFL/geocompr.robinlovelace.net.html}
}

@article{nordvik2019,
  title = {Capitalization of Neighbourhood Diversity and Segregation},
  author = {Nordvik, Viggo and Osland, Liv and Thorsen, Inge and Thorsen, Ingrid Sandvig},
  date = {2019-07-02},
  journaltitle = {Environment and Planning A: Economy and Space},
  shortjournal = {Environ Plan A},
  volume = {51},
  number = {8},
  pages = {1775--1799},
  issn = {0308-518X},
  doi = {10.1177/0308518X19861108},
  url = {https://doi.org/10.1177/0308518X19861108},
  urldate = {2020-01-10}
}

@article{nosek2015,
  title = {Promoting an Open Research Culture},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. L. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06-26},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aab2374},
  urldate = {2020-09-11},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/8PJSTSZH/Nosek et al. - 2015 - Promoting an open research culture.pdf}
}

@article{nosek2015a,
  title = {Promoting an {{Open Research Culture}}},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. L. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  langid = {english},
  keywords = {done}
}

@article{nosek2015b,
  title = {Promoting an {{Open Research Culture}}},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. L. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  langid = {english},
  keywords = {done}
}

@article{nosek2015c,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Nosek, Brian A. and {et al}},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{nosek2015d,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Nosek, Brian A. and {et al}},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{nosekEstimatingReproducibilityPsychological2015,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Nosek, Brian A. and {et al}},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{nosekEstimatingReproducibilityPsychological2015a,
  title = {Estimating the {{Reproducibility}} of {{Psychological Science}}},
  author = {Nosek, Brian A. and {et al}},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  keywords = {done}
}

@article{nosekPromotingOpenResearch2015,
  title = {Promoting an {{Open Research Culture}}},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. L. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  langid = {english},
  keywords = {done}
}

@article{nosekPromotingOpenResearch2015a,
  title = {Promoting an {{Open Research Culture}}},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. L. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  langid = {english},
  keywords = {done}
}

@article{nust2017,
  title = {Opening the {{Publication Process}} with {{Executable Research Compendia}}},
  author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
  date = {2017-01},
  journaltitle = {D-Lib Magazine},
  shortjournal = {D-Lib Magazine},
  volume = {23},
  number = {1/2},
  issn = {1082-9873},
  doi = {10.1045/january2017-nuest},
  url = {http://www.dlib.org/dlib/january17/nuest/01nuest.html},
  urldate = {2020-09-11},
  langid = {english}
}

@article{nust2017a,
  title = {Opening the {{Publication Process}} with {{Executable Research Compendia}}},
  author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
  date = {2017-01},
  journaltitle = {D-Lib Magazine},
  volume = {23},
  number = {1/2},
  issn = {1082-9873},
  doi = {10.1045/january2017-nuest},
  langid = {english}
}

@article{nust2017b,
  title = {Opening the {{Publication Process}} with {{Executable Research Compendia}}},
  author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
  date = {2017-01},
  journaltitle = {D-Lib Magazine},
  volume = {23},
  number = {1/2},
  issn = {1082-9873},
  doi = {10.1045/january2017-nuest},
  langid = {english}
}

@article{nustOpeningPublicationProcess2017,
  title = {Opening the {{Publication Process}} with {{Executable Research Compendia}}},
  author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
  date = {2017-01},
  journaltitle = {D-Lib Magazine},
  volume = {23},
  number = {1/2},
  issn = {1082-9873},
  doi = {10.1045/january2017-nuest},
  langid = {english}
}

@article{nustOpeningPublicationProcess2017a,
  title = {Opening the {{Publication Process}} with {{Executable Research Compendia}}},
  author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
  date = {2017-01},
  journaltitle = {D-Lib Magazine},
  volume = {23},
  number = {1/2},
  issn = {1082-9873},
  doi = {10.1045/january2017-nuest},
  langid = {english}
}

@article{oetiker,
  title = {The {{Not So Short Introduction}} to {{LATEX}} 2ε},
  author = {Oetiker, Tobias and Partl, Hubert and Hyna, Irene and Schlegl, Elisabeth},
  pages = {153},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/DWCVPUIN/Oetiker et al. - The Not So Short Introduction to LATEX 2ε.pdf}
}

@article{opensciencecollaboration2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {Open Science Collaboration},
  date = {2015},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  eprint = {https://science.sciencemag.org/content/349/6251/aac4716.full.pdf},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  doi = {10.1126/science.aac4716},
  url = {https://science.sciencemag.org/content/349/6251/aac4716},
  abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that we already know this belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  elocation-id = {aac4716}
}

@article{osland2007,
  title = {Housing Price Gradients in a Geography with One Dominating Center},
  author = {Osland, L and Thorsen, I and Gitlesen, JP},
  date = {2007},
  journaltitle = {Journal of Real Estate Research},
  volume = {29},
  number = {3},
  pages = {321--346},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{osland2008,
  title = {Effects on Housing Prices of Urban Attraction and Labor Market Accessibility},
  author = {Osland, L and Thorsen, I},
  date = {2008},
  journaltitle = {Environment and Planning A},
  volume = {40},
  number = {10},
  pages = {2490--2509},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{osland2010,
  title = {An Application of Spatial Econometrics in Relation to Hedonic House Price Modelling},
  author = {Osland, L},
  date = {2010},
  journaltitle = {Journal of Real Estate Research},
  volume = {32},
  pages = {289--320},
  date-modified = {2014-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{osland2012,
  title = {Housing Prices and Multiple Employment Nodes: {{Is}} the Relationship Nonmonotonic?},
  author = {Osland, L and Pryce, G},
  date = {2012},
  journaltitle = {Housing Studies},
  volume = {27},
  pages = {1182--1208},
  date-modified = {2014-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{osland2013,
  title = {Spatial Impacts, Local Labour Market Characteristics and Housing Prices},
  author = {Osland, L and Thorsen, I},
  date = {2013},
  journaltitle = {Urban Studies},
  volume = {10},
  number = {50},
  pages = {2063--2083},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{pace1998,
  title = {Appraisal Using Generalized Additive Models},
  author = {Pace, RK},
  date = {1998},
  journaltitle = {Journal of Real Estate Research},
  volume = {15},
  pages = {77--99},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{PandocPandocUser,
  title = {Pandoc - {{Pandoc User}}'s {{Guide}}}
}

@book{PandocPandocUsera,
  title = {Pandoc - {{Pandoc User}}'s {{Guide}}}
}

@article{peng2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12-02},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  url = {https://science.sciencemag.org/content/334/6060/1226},
  urldate = {2020-08-19},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/TNKC5BRR/Peng - 2011 - Reproducible Research in Computational Science.pdf;/Users/agwd/Zotero/storage/N5V26MV8/1226.html}
}

@article{peng2011a,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  copyright = {Copyright © 2011, American Association for the Advancement of Science},
  langid = {english},
  keywords = {done}
}

@article{peng2011b,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  copyright = {Copyright © 2011, American Association for the Advancement of Science},
  langid = {english},
  keywords = {done}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  copyright = {Copyright © 2011, American Association for the Advancement of Science},
  langid = {english},
  keywords = {done}
}

@article{pengReproducibleResearchComputational2011a,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  copyright = {Copyright © 2011, American Association for the Advancement of Science},
  langid = {english},
  keywords = {done}
}

@article{piwowar2018,
  title = {The State of {{OA}}: A Large-Scale Analysis of the Prevalence and Impact of {{Open Access}} Articles},
  shorttitle = {The State of {{OA}}},
  author = {Piwowar, Heather and Priem, Jason and Larivière, Vincent and Alperin, Juan Pablo and Matthias, Lisa and Norlander, Bree and Farley, Ashley and West, Jevin and Haustein, Stefanie},
  date = {2018-02-13},
  journaltitle = {PeerJ},
  shortjournal = {PeerJ},
  volume = {6},
  pages = {e4375},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10.7717/peerj.4375},
  url = {https://peerj.com/articles/4375},
  urldate = {2020-12-04},
  abstract = {Despite growing interest in Open Access (OA) to scholarly literature, there is an unmet need for large-scale, up-to-date, and reproducible studies assessing the prevalence and characteristics of OA. We address this need using oaDOI, an open online service that determines OA status for 67 million articles. We use three samples, each of 100,000 articles, to investigate OA in three populations: (1) all journal articles assigned a Crossref DOI, (2) recent journal articles indexed in Web of Science, and (3) articles viewed by users of Unpaywall, an open-source browser extension that lets users find OA articles using oaDOI. We estimate that at least 28\% of the scholarly literature is OA (19M in total) and that this proportion is growing, driven particularly by growth in Gold and Hybrid. The most recent year analyzed (2015) also has the highest percentage of OA (45\%). Because of this growth, and the fact that readers disproportionately access newer articles, we find that Unpaywall users encounter OA quite frequently: 47\% of articles they view are OA. Notably, the most common mechanism for OA is not Gold, Green, or Hybrid OA, but rather an under-discussed category we dub Bronze: articles made free-to-read on the publisher website, without an explicit Open license. We also examine the citation impact of OA articles, corroborating the so-called open-access citation advantage: accounting for age and discipline, OA articles receive 18\% more citations than average, an effect driven primarily by Green and Hybrid OA. We encourage further research using the free oaDOI service, as a way to inform OA policy and practice.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/693L4FCF/Piwowar et al. - 2018 - The state of OA a large-scale analysis of the pre.pdf}
}

@article{plaut1998,
  title = {Endogenous Identification of Multiple Housing Price Centers in Metropolitan Areas},
  author = {Plaut, PO and Plaut, SE},
  date = {1998},
  journaltitle = {Journal of Housing Economics},
  volume = {7},
  pages = {193--217},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{portnov2010,
  title = {On the Suitability of Income Inequality Measures for Regional Analysis: {{Some}} Evidence from Simulation Analysis and Bootstrapping Tests},
  shorttitle = {On the Suitability of Income Inequality Measures for Regional Analysis},
  author = {Portnov, Boris A. and Felsenstein, Daniel},
  date = {2010-12-01},
  journaltitle = {Socio-Economic Planning Sciences},
  shortjournal = {Socio-Economic Planning Sciences},
  volume = {44},
  number = {4},
  pages = {212--219},
  issn = {0038-0121},
  doi = {10.1016/j.seps.2010.04.002},
  url = {http://www.sciencedirect.com/science/article/pii/S0038012110000145},
  urldate = {2019-09-13},
  abstract = {The paper looks at the sensitivity of commonly used income inequality measures to changes in the ranking, size and number of regions into which a country is divided. During the analysis, several test distributions of populations and incomes are compared with a ‘reference’ distribution, characterized by an even distribution of population across regional subdivisions. Random permutation tests are also run to determine whether inequality measures commonly used in regional analysis produce meaningful estimates when applied to regions of different population size. The results show that only the population weighted coefficient of variation (Williamson’s index) and population-weighted Gini coefficient may be considered sufficiently reliable inequality measures, when applied to countries with a small number of regions and with varying population sizes.},
  keywords = {Bootstrapping,Inequality measures,Random permutation tests,Regions},
  file = {/Users/agwd/Zotero/storage/Y2JT8UWY/Portnov and Felsenstein - 2010 - On the suitability of income inequality measures f.pdf;/Users/agwd/Zotero/storage/6NIQPMMI/S0038012110000145.html}
}

@article{ram2013,
  title = {Git Can Facilitate Greater Reproducibility and Increased Transparency in Science},
  author = {Ram, Karthik},
  date = {2013-02-28},
  journaltitle = {Source Code for Biology and Medicine},
  shortjournal = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  url = {https://doi.org/10.1186/1751-0473-8-7},
  urldate = {2020-08-26},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
  file = {/Users/agwd/Zotero/storage/N2EZSANN/Ram - 2013 - Git can facilitate greater reproducibility and inc.pdf;/Users/agwd/Zotero/storage/FFMA66JW/1751-0473-8-7.html}
}

@article{ram2013a,
  title = {Git {{Can Facilitate Greater Reproducibility}} and {{Increased Transparency}} in {{Science}}},
  author = {Ram, Karthik},
  date = {2013-02},
  journaltitle = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.}
}

@article{ram2013b,
  title = {Git {{Can Facilitate Greater Reproducibility}} and {{Increased Transparency}} in {{Science}}},
  author = {Ram, Karthik},
  date = {2013-02},
  journaltitle = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.}
}

@article{ramGitCanFacilitate2013,
  title = {Git {{Can Facilitate Greater Reproducibility}} and {{Increased Transparency}} in {{Science}}},
  author = {Ram, Karthik},
  date = {2013-02},
  journaltitle = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.}
}

@article{ramGitCanFacilitate2013a,
  title = {Git {{Can Facilitate Greater Reproducibility}} and {{Increased Transparency}} in {{Science}}},
  author = {Ram, Karthik},
  date = {2013-02},
  journaltitle = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.}
}

@book{ramsey,
  title = {Noweb {{Home Page}}},
  author = {Ramsey, Norman},
  keywords = {done}
}

@article{ramsey1969,
  title = {Tests for Specification Errors in Classical Linear Least Squares Regression Analysis},
  author = {Ramsey, JB},
  date = {1969},
  journaltitle = {Journal of Royal Statistical Society B},
  volume = {31},
  number = {2},
  pages = {350--371},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{ramseya,
  title = {Noweb {{Home Page}}},
  author = {Ramsey, Norman},
  keywords = {done}
}

@book{ramseyNowebHomePage,
  title = {Noweb {{Home Page}}},
  author = {Ramsey, Norman},
  keywords = {done}
}

@book{ramseyNowebHomePagea,
  title = {Noweb {{Home Page}}},
  author = {Ramsey, Norman},
  keywords = {done}
}

@manual{rcoreteam2020,
  type = {manual},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}}
}

@book{rcoreteam2020a,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}}
}

@book{rcoreteam2020b,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  keywords = {done}
}

@book{rcoreteam2020c,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  keywords = {done}
}

@book{rcoreteamLanguageEnvironmentStatistical2020,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  keywords = {done}
}

@book{rcoreteamLanguageEnvironmentStatistical2020a,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  location = {{Vienna, Austria}},
  keywords = {done}
}

@article{rendell2019,
  title = {Opinion | {{I}} like {{Elizabeth Warren}}. {{Too}} Bad She’s a Hypocrite.},
  author = {Rendell, Ed},
  year = {2019-09-11T06:53-500},
  journaltitle = {Washington Post},
  issn = {0190-8286},
  url = {https://www.washingtonpost.com/opinions/i-like-elizabeth-warren-too-bad-shes-a-hypocrite/2019/09/11/409d5ed0-d4d3-11e9-86ac-0f250cc91758_story.html},
  urldate = {2019-09-12},
  abstract = {Her campaign finance promises are hypocritical.},
  entrysubtype = {newspaper},
  journalsubtitle = {Opinions},
  langid = {american},
  file = {/Users/agwd/Zotero/storage/28CY24MP/409d5ed0-d4d3-11e9-86ac-0f250cc91758_story.html}
}

@manual{revelle2020,
  type = {manual},
  title = {Psych: {{Procedures}} for Psychological, Psychometric, and Personality Research},
  author = {Revelle, William},
  date = {2020},
  location = {{Evanston, Illinois}},
  url = {https://CRAN.R-project.org/package=psych},
  organization = {{Northwestern University}}
}

@book{riederer,
  title = {R {{Markdown Cookbook}}},
  author = {Riederer, Christophe Dervieux, Emily, Yihui Xie},
  url = {https://bookdown.org/yihui/rmarkdown-cookbook/},
  urldate = {2020-08-31},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  file = {/Users/agwd/Zotero/storage/XRX2VJVT/rmarkdown-cookbook.html}
}

@book{riedererMarkdownCookbook,
  title = {R {{Markdown Cookbook}}},
  author = {Riederer, Christophe Dervieux, Yihui Xie, Emily},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  keywords = {done}
}

@book{riedererMarkdownCookbooka,
  title = {R {{Markdown Cookbook}}},
  author = {Riederer, Christophe Dervieux, Yihui Xie, Emily},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  keywords = {done}
}

@online{rognsvag2019,
  title = {Revisorforeininga: – Veldig alvorleg sak},
  shorttitle = {Revisorforeininga},
  author = {Rognsvåg, Silje},
  date = {2019-04-10},
  url = {https://www.nrk.no/norge/revisorforeininga_-_-veldig-alvorleg-sak-1.14510594},
  urldate = {2019-04-10},
  abstract = {Per Hanstad i Den norske revisorforeininga meiner at det er lite truverdig at Ap-politikar Liadal skuldar på rot i reiserekningssaka.},
  langid = {nynorsk},
  organization = {{NRK}},
  file = {/Users/agwd/Zotero/storage/R6AN9F7A/revisorforeininga_-_-veldig-alvorleg-sak-1.html}
}

@inproceedings{rosenthal1979,
  title = {The File Drawer Problem and Tolerance for Null Results.},
  author = {Rosenthal, R.},
  date = {1979},
  file = {/Users/agwd/Zotero/storage/EL2FFM8Y/Rosenthal1979PsychBulletin.pdf}
}

@inproceedings{rosenthal1979a,
  title = {The {{File Drawer Problem}} and {{Tolerance}} for {{Null Results}}.},
  author = {Rosenthal, R.},
  date = {1979},
  volume = {86},
  pages = {638--641},
  publisher = {{Psychological Bulletin}},
  keywords = {done}
}

@inproceedings{rosenthal1979b,
  title = {The {{File Drawer Problem}} and {{Tolerance}} for {{Null Results}}.},
  author = {Rosenthal, R.},
  date = {1979},
  volume = {86},
  pages = {638--641},
  publisher = {{Psychological Bulletin}},
  keywords = {done}
}

@inproceedings{rosenthalFileDrawerProblem1979,
  title = {The {{File Drawer Problem}} and {{Tolerance}} for {{Null Results}}.},
  author = {Rosenthal, R.},
  date = {1979},
  volume = {86},
  pages = {638--641},
  publisher = {{Psychological Bulletin}},
  keywords = {done}
}

@inproceedings{rosenthalFileDrawerProblem1979a,
  title = {The {{File Drawer Problem}} and {{Tolerance}} for {{Null Results}}.},
  author = {Rosenthal, R.},
  date = {1979},
  volume = {86},
  pages = {638--641},
  publisher = {{Psychological Bulletin}},
  keywords = {done}
}

@article{rossi,
  title = {Measuring the Tracking Error  of Exchange Traded Funds:  An Unobserved Components Approach},
  author = {Rossi, Giuliano De},
  pages = {36},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/3SSAPAIW/Rossi - Measuring the tracking error  of exchange traded f.pdf}
}

@book{rstudioteam2020,
  title = {{{RStudio}}: {{Integrated}} Development Environment for r},
  author = {{RStudio Team}},
  date = {2020},
  location = {{Boston, MA}},
  url = {http://www.rstudio.com/},
  organization = {{RStudio, PBC.}}
}

@book{rstudioteam2020a,
  title = {{{RStudio}}: {{Integrated Development Environment}} for r},
  author = {{RStudio Team}},
  date = {2020},
  publisher = {{RStudio, PBC.}},
  location = {{Boston, MA}}
}

@book{rstudioteam2020b,
  title = {{{RStudio}}: {{Integrated Development Environment}} for r},
  author = {{RStudio Team}},
  date = {2020},
  publisher = {{RStudio, PBC.}},
  location = {{Boston, MA}}
}

@book{rstudioteamRStudioIntegratedDevelopment2020,
  title = {{{RStudio}}: {{Integrated Development Environment}} for r},
  author = {{RStudio Team}},
  date = {2020},
  publisher = {{RStudio, PBC.}},
  location = {{Boston, MA}}
}

@book{rstudioteamRStudioIntegratedDevelopment2020a,
  title = {{{RStudio}}: {{Integrated Development Environment}} for r},
  author = {{RStudio Team}},
  date = {2020},
  publisher = {{RStudio, PBC.}},
  location = {{Boston, MA}}
}

@article{schwab1995,
  title = {Reproducible {{Electronic Documents}}},
  author = {Schwab, Matthias and Karrenbach, Martin and Claerbout, Jon},
  date = {1995},
  pages = {14},
  abstract = {To organize computational scientific research and hence to conveniently transfer our technology, we impose a simple filing discipline on the authors in our laboratory. A document's makefile includes laboratory-wide standard rules that offer readers these four standard commands: make burn removes the document's result figures, make build recomputes them, make view displays the figures, and make clean removes any intermediate files. Although we developed these standards to aid readers we discovered that authors are often the principal beneficiaries.},
  langid = {english},
  keywords = {done}
}

@article{schwab1995a,
  title = {Reproducible {{Electronic Documents}}},
  author = {Schwab, Matthias and Karrenbach, Martin and Claerbout, Jon},
  date = {1995},
  pages = {14},
  abstract = {To organize computational scientific research and hence to conveniently transfer our technology, we impose a simple filing discipline on the authors in our laboratory. A document's makefile includes laboratory-wide standard rules that offer readers these four standard commands: make burn removes the document's result figures, make build recomputes them, make view displays the figures, and make clean removes any intermediate files. Although we developed these standards to aid readers we discovered that authors are often the principal beneficiaries.},
  langid = {english},
  keywords = {done}
}

@article{schwabReproducibleElectronicDocuments1995,
  title = {Reproducible {{Electronic Documents}}},
  author = {Schwab, Matthias and Karrenbach, Martin and Claerbout, Jon},
  date = {1995},
  pages = {14},
  abstract = {To organize computational scientific research and hence to conveniently transfer our technology, we impose a simple filing discipline on the authors in our laboratory. A document's makefile includes laboratory-wide standard rules that offer readers these four standard commands: make burn removes the document's result figures, make build recomputes them, make view displays the figures, and make clean removes any intermediate files. Although we developed these standards to aid readers we discovered that authors are often the principal beneficiaries.},
  langid = {english},
  keywords = {done}
}

@article{schwabReproducibleElectronicDocuments1995a,
  title = {Reproducible {{Electronic Documents}}},
  author = {Schwab, Matthias and Karrenbach, Martin and Claerbout, Jon},
  date = {1995},
  pages = {14},
  abstract = {To organize computational scientific research and hence to conveniently transfer our technology, we impose a simple filing discipline on the authors in our laboratory. A document's makefile includes laboratory-wide standard rules that offer readers these four standard commands: make burn removes the document's result figures, make build recomputes them, make view displays the figures, and make clean removes any intermediate files. Although we developed these standards to aid readers we discovered that authors are often the principal beneficiaries.},
  langid = {english},
  keywords = {done}
}

@article{simmons2011,
  title = {False-Positive Psychology: {{Undisclosed}} Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  date = {2011},
  journaltitle = {Psychological Science},
  volume = {22},
  number = {11},
  eprint = {https://doi.org/10.1177/0956797611417632},
  pages = {1359--1366},
  doi = {10.1177/0956797611417632},
  url = {https://doi.org/10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.}
}

@article{simmons2011a,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  date = {2011},
  journaltitle = {Psychological Science},
  volume = {22},
  number = {11},
  eprint = {22006061},
  eprinttype = {pmid},
  pages = {1359--1366},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (\$\textbackslash leq\$ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  keywords = {done}
}

@article{simmons2011b,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  date = {2011},
  journaltitle = {Psychological Science},
  volume = {22},
  number = {11},
  eprint = {22006061},
  eprinttype = {pmid},
  pages = {1359--1366},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (\$\textbackslash leq\$ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  keywords = {done}
}

@article{simmonsFalsePositivePsychologyUndisclosed2011,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  date = {2011},
  journaltitle = {Psychological Science},
  volume = {22},
  number = {11},
  eprint = {22006061},
  eprinttype = {pmid},
  pages = {1359--1366},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (\$\textbackslash leq\$ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  keywords = {done}
}

@article{simmonsFalsePositivePsychologyUndisclosed2011a,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  date = {2011},
  journaltitle = {Psychological Science},
  volume = {22},
  number = {11},
  eprint = {22006061},
  eprinttype = {pmid},
  pages = {1359--1366},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (\$\textbackslash leq\$ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  keywords = {done}
}

@article{smith2008,
  title = {Moving from an {{Efficient}} to a {{Behavioral Market Hypothesis}}},
  author = {Smith, Donald J.},
  date = {2008},
  journaltitle = {Journal of Behavioral Finance},
  volume = {9},
  number = {2},
  pages = {51--52},
  issn = {1542-7560},
  doi = {10.1080/15427560802093589},
  abstract = {Behavioral finance typically is introduced in investments courses in the context of the efficient markets hypothesis (see, e.g., the widely used textbooks by Bodie, Kane, and Marcus [2002] and Reilly and Brown [2003] ). This note offers a diagrammatic approach to “position” visually behavioral finance between the information available to market participants and their investment decisions.},
  keywords = {Business;}
}

@article{starr2015,
  title = {Achieving Human and Machine Accessibility of Cited Data in Scholarly Publications},
  author = {Starr, Joan and Castro, Eleni and Crosas, Mercè and Dumontier, Michel and Downs, Robert R. and Duerr, Ruth and Haak, Laurel L. and Haendel, Melissa and Herman, Ivan and Hodson, Simon and Hourclé, Joe and Kratz, John Ernest and Lin, Jennifer and Nielsen, Lars Holm and Nurnberger, Amy and Proell, Stefan and Rauber, Andreas and Sacchi, Simone and Smith, Arthur and Taylor, Mike and Clark, Tim},
  date = {2015-05-27},
  journaltitle = {PeerJ Computer Science},
  shortjournal = {PeerJ Comput. Sci.},
  volume = {1},
  pages = {e1},
  publisher = {{PeerJ Inc.}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.1},
  url = {https://peerj.com/articles/cs-1},
  urldate = {2020-12-04},
  abstract = {Reproducibility and reusability of research results is an important concern in scientific communication and science policy. A foundational element of reproducibility and reusability is the open and persistently available presentation of research data. However, many common approaches for primary data publication in use today do not achieve sufficient long-term robustness, openness, accessibility or uniformity. Nor do they permit comprehensive exploitation by modern Web technologies. This has led to several authoritative studies recommending uniform direct citation of data archived in persistent repositories. Data are to be considered as first-class scholarly objects, and treated similarly in many ways to cited and archived scientific and scholarly literature. Here we briefly review the most current and widely agreed set of principle-based recommendations for scholarly data citation, the Joint Declaration of Data Citation Principles (JDDCP). We then present a framework for operationalizing the JDDCP; and a set of initial recommendations on identifier schemes, identifier resolution behavior, required metadata elements, and best practices for realizing programmatic machine actionability of cited data. The main target audience for the common implementation guidelines in this article consists of publishers, scholarly organizations, and persistent data repositories, including technical staff members in these organizations. But ordinary researchers can also benefit from these recommendations. The guidance provided here is intended to help achieve widespread, uniform human and machine accessibility of deposited data, in support of significantly improved verification, validation, reproducibility and re-use of scholarly/scientific data.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/INH6TNP6/Starr et al. - 2015 - Achieving human and machine accessibility of cited.pdf;/Users/agwd/Zotero/storage/NL9ELZP3/cs-1.html}
}

@article{steiniger2013,
  title = {The 2012 Free and Open Source {{GIS}} Software Map – {{A}} Guide to Facilitate Research, Development, and Adoption},
  author = {Steiniger, Stefan and Hunter, Andrew J. S.},
  date = {2013-05-01},
  journaltitle = {Computers, Environment and Urban Systems},
  shortjournal = {Computers, Environment and Urban Systems},
  volume = {39},
  pages = {136--150},
  issn = {0198-9715},
  doi = {10.1016/j.compenvurbsys.2012.10.003},
  url = {http://www.sciencedirect.com/science/article/pii/S0198971512000890},
  urldate = {2020-12-04},
  abstract = {Over the last decade an increasing number of free and open source software projects have been founded that concentrate on developing several types of software for geographic data collection, storage, analysis and visualization. We first identify the drivers of such software projects and identify different types of geographic information software, e.g. desktop GIS, remote sensing software, server GIS etc. We then list the major projects for each software category. Afterwards we discuss the points that should be considered if free and open source software is to be selected for use in business and research, such as software functionality, license types and their restrictions, developer and user community characteristics, etc. Finally possible future developments are addressed.},
  langid = {english},
  keywords = {FOSS4G,Free software,GIS software,Open source,Overview,Software selection},
  file = {/Users/agwd/Zotero/storage/ZGLLCTME/Steiniger og Hunter - 2013 - The 2012 free and open source GIS software map – A.pdf;/Users/agwd/Zotero/storage/9JWDCULE/S0198971512000890.html}
}

@book{tierney,
  title = {{{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  url = {https://rmd4sci.njtierney.com/},
  urldate = {2020-08-23},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  file = {/Users/agwd/Zotero/storage/6G66Z9WU/rmd4sci.njtierney.com.html}
}

@book{tierneya,
  title = {13 {{Citing Articles}} \& {{Bibliography Styles}} | {{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  url = {https://rmd4sci.njtierney.com/},
  urldate = {2020-08-23},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  file = {/Users/agwd/Zotero/storage/WD43YPUN/citing-articles-bibliography-styles.html}
}

@book{tierneyb,
  title = {{{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  keywords = {done}
}

@book{tierneyc,
  title = {{{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  keywords = {done}
}

@book{tierneyRMarkdownScientists,
  title = {{{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  keywords = {done}
}

@book{tierneyRMarkdownScientistsa,
  title = {{{RMarkdown}} for {{Scientists}}},
  author = {Tierney, Nicholas},
  abstract = {A book created for a 3 hour workshop on rmarkdown},
  keywords = {done}
}

@book{vagane2011,
  title = {Den Nasjonale Reisevaneundersøkelsen - 2009},
  author = {Vågane, L and Brechan, I and Hjorthol, R},
  date = {2011},
  publisher = {{The Institute for Transport Economics}},
  location = {{TØI Report 1130}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{vaona2009,
  title = {Spatial Autocorrelation or Model Misspecification? {{The}} Help from {{RESET}} and the Curse of Small Samples.},
  author = {Vaona, A},
  date = {2009},
  journaltitle = {Letters of Spatial Resource Sciences},
  volume = {2},
  pages = {53--59},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@article{waddell1993,
  title = {Residential Property Values in a Multinodal Urban Area: {{New}} Evidence on the Implicit Price of Location},
  author = {Waddell, P and Berry, BJL and Hoch, I},
  date = {1993},
  journaltitle = {Journal of real estate finance and economics},
  volume = {7},
  pages = {117--141},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@manual{waring2020,
  type = {manual},
  title = {Skimr: {{Compact}} and Flexible Summaries of Data},
  author = {Waring, Elin and Quinn, Michael and McNamara, Amelia and de la Rubia, Eduardo Arino and Zhu, Hao and Ellis, Shannon},
  options = {useprefix=true},
  date = {2020},
  url = {https://CRAN.R-project.org/package=skimr}
}

@book{wickham,
  title = {The Tidyverse Style Guide},
  author = {Wickham, Hadley},
  url = {https://style.tidyverse.org/},
  urldate = {2020-08-27},
  abstract = {The tidyverse style guide},
  file = {/Users/agwd/Zotero/storage/MEMY2VNN/style.tidyverse.org.html}
}

@article{wickham2014,
  title = {Tidy Data},
  author = {Wickham, Hadley},
  date = {2014-09},
  journaltitle = {The American Statistician},
  volume = {14},
  doi = {10.18637/jss.v059.i10}
}

@book{wickham2016,
  title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
  shorttitle = {R for Data Science},
  author = {Wickham, Hadley and Grolemund, Garrett},
  date = {2016},
  pages = {XXV, 492},
  publisher = {{O'Reilly}},
  location = {{Beijing}},
  isbn = {978-1-4919-1039-9},
  langid = {english},
  pagetotal = {xxv+492},
  keywords = {Computer programs; Information visualization,Computer programs; R (Computer program language); Statistiske metoder; R-språk; programmering; R; statistikk; data science; datavitenskap,Data mining}
}

@book{wickham2016a,
  title = {R for {{Data Science}}: {{Import}}, {{Tidy}}, {{Transform}}, {{Visualize}}, and {{Model Data}}},
  shorttitle = {R for {{Data Science}}},
  author = {Wickham, Hadley and Grolemund, Garrett},
  date = {2016},
  publisher = {{O'Reilly}},
  location = {{Beijing}},
  isbn = {978-1-4919-1039-9},
  langid = {english},
  lccn = {006.312 Wic, 519.2 W63r, 006.312 WIC}
}

@book{wickham2016b,
  title = {R for {{Data Science}}: {{Import}}, {{Tidy}}, {{Transform}}, {{Visualize}}, and {{Model Data}}},
  shorttitle = {R for {{Data Science}}},
  author = {Wickham, Hadley and Grolemund, Garrett},
  date = {2016},
  publisher = {{O'Reilly}},
  location = {{Beijing}},
  isbn = {978-1-4919-1039-9},
  langid = {english},
  lccn = {006.312 Wic, 519.2 W63r, 006.312 WIC}
}

@book{wickhamDataScienceImport2016,
  title = {R for {{Data Science}}: {{Import}}, {{Tidy}}, {{Transform}}, {{Visualize}}, and {{Model Data}}},
  shorttitle = {R for {{Data Science}}},
  author = {Wickham, Hadley and Grolemund, Garrett},
  date = {2016},
  publisher = {{O'Reilly}},
  location = {{Beijing}},
  isbn = {978-1-4919-1039-9},
  langid = {english},
  lccn = {006.312 Wic, 519.2 W63r, 006.312 WIC}
}

@book{wickhamDataScienceImport2016a,
  title = {R for {{Data Science}}: {{Import}}, {{Tidy}}, {{Transform}}, {{Visualize}}, and {{Model Data}}},
  shorttitle = {R for {{Data Science}}},
  author = {Wickham, Hadley and Grolemund, Garrett},
  date = {2016},
  publisher = {{O'Reilly}},
  location = {{Beijing}},
  isbn = {978-1-4919-1039-9},
  langid = {english},
  lccn = {006.312 Wic, 519.2 W63r, 006.312 WIC}
}

@article{wikipedia2020,
  title = {Meta-{{Analysis}}},
  author = {{wikipedia}},
  date = {2020-08},
  journaltitle = {Wikipedia},
  abstract = {A meta-analysis is a statistical analysis that combines the results of multiple scientific studies. Meta-analysis can be performed when there are multiple scientific studies addressing the same question, with each individual study reporting measurements that are expected to have some degree of error. The aim then is to use approaches from statistics to derive a pooled estimate closest to the unknown common truth based on how this error is perceived. Existing methods for meta-analysis yield a weighted average from the results of the individual studies, and what differs is the manner in which these weights are allocated and also the manner in which the uncertainty is computed around the point estimate thus generated. In addition to providing an estimate of the unknown common truth, meta-analysis has the capacity to contrast results from different studies and identify patterns among study results, sources of disagreement among those results, or other interesting relationships that may come to light in the context of multiple studies.A key benefit of this approach is the aggregation of information leading to a higher statistical power and more robust point estimate than is possible from the measure derived from any individual study. However, in performing a meta-analysis, an investigator must make choices which can affect the results, including deciding how to search for studies, selecting studies based on a set of objective criteria, dealing with incomplete data, analyzing the data, and accounting for or choosing not to account for publication bias. Judgment calls made in completing a meta-analysis may affect the results. For example, Wanous and colleagues examined four pairs of meta-analyses on the four topics of (a) job performance and satisfaction relationship, (b) realistic job previews, (c) correlates of role conflict and ambiguity, and (d) the job satisfaction and absenteeism relationship, and illustrated how various judgement calls made by the researchers produced different results.Meta-analyses are often, but not always, important components of a systematic review procedure. For instance, a meta-analysis may be conducted on several clinical trials of a medical treatment, in an effort to obtain a better understanding of how well the treatment works. Here it is convenient to follow the terminology used by the Cochrane Collaboration, and use "meta-analysis" to refer to statistical methods of combining evidence, leaving other aspects of 'research synthesis' or 'evidence synthesis', such as combining information from qualitative studies, for the more general context of systematic reviews. A meta-analysis is a secondary source.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  keywords = {done}
}

@article{wikipedia2020a,
  title = {Meta-{{Analysis}}},
  author = {{wikipedia}},
  date = {2020-08},
  journaltitle = {Wikipedia},
  abstract = {A meta-analysis is a statistical analysis that combines the results of multiple scientific studies. Meta-analysis can be performed when there are multiple scientific studies addressing the same question, with each individual study reporting measurements that are expected to have some degree of error. The aim then is to use approaches from statistics to derive a pooled estimate closest to the unknown common truth based on how this error is perceived. Existing methods for meta-analysis yield a weighted average from the results of the individual studies, and what differs is the manner in which these weights are allocated and also the manner in which the uncertainty is computed around the point estimate thus generated. In addition to providing an estimate of the unknown common truth, meta-analysis has the capacity to contrast results from different studies and identify patterns among study results, sources of disagreement among those results, or other interesting relationships that may come to light in the context of multiple studies.A key benefit of this approach is the aggregation of information leading to a higher statistical power and more robust point estimate than is possible from the measure derived from any individual study. However, in performing a meta-analysis, an investigator must make choices which can affect the results, including deciding how to search for studies, selecting studies based on a set of objective criteria, dealing with incomplete data, analyzing the data, and accounting for or choosing not to account for publication bias. Judgment calls made in completing a meta-analysis may affect the results. For example, Wanous and colleagues examined four pairs of meta-analyses on the four topics of (a) job performance and satisfaction relationship, (b) realistic job previews, (c) correlates of role conflict and ambiguity, and (d) the job satisfaction and absenteeism relationship, and illustrated how various judgement calls made by the researchers produced different results.Meta-analyses are often, but not always, important components of a systematic review procedure. For instance, a meta-analysis may be conducted on several clinical trials of a medical treatment, in an effort to obtain a better understanding of how well the treatment works. Here it is convenient to follow the terminology used by the Cochrane Collaboration, and use "meta-analysis" to refer to statistical methods of combining evidence, leaving other aspects of 'research synthesis' or 'evidence synthesis', such as combining information from qualitative studies, for the more general context of systematic reviews. A meta-analysis is a secondary source.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  keywords = {done}
}

@article{wikipediaMetaAnalysis2020,
  title = {Meta-{{Analysis}}},
  author = {{wikipedia}},
  date = {2020-08},
  journaltitle = {Wikipedia},
  abstract = {A meta-analysis is a statistical analysis that combines the results of multiple scientific studies. Meta-analysis can be performed when there are multiple scientific studies addressing the same question, with each individual study reporting measurements that are expected to have some degree of error. The aim then is to use approaches from statistics to derive a pooled estimate closest to the unknown common truth based on how this error is perceived. Existing methods for meta-analysis yield a weighted average from the results of the individual studies, and what differs is the manner in which these weights are allocated and also the manner in which the uncertainty is computed around the point estimate thus generated. In addition to providing an estimate of the unknown common truth, meta-analysis has the capacity to contrast results from different studies and identify patterns among study results, sources of disagreement among those results, or other interesting relationships that may come to light in the context of multiple studies.A key benefit of this approach is the aggregation of information leading to a higher statistical power and more robust point estimate than is possible from the measure derived from any individual study. However, in performing a meta-analysis, an investigator must make choices which can affect the results, including deciding how to search for studies, selecting studies based on a set of objective criteria, dealing with incomplete data, analyzing the data, and accounting for or choosing not to account for publication bias. Judgment calls made in completing a meta-analysis may affect the results. For example, Wanous and colleagues examined four pairs of meta-analyses on the four topics of (a) job performance and satisfaction relationship, (b) realistic job previews, (c) correlates of role conflict and ambiguity, and (d) the job satisfaction and absenteeism relationship, and illustrated how various judgement calls made by the researchers produced different results.Meta-analyses are often, but not always, important components of a systematic review procedure. For instance, a meta-analysis may be conducted on several clinical trials of a medical treatment, in an effort to obtain a better understanding of how well the treatment works. Here it is convenient to follow the terminology used by the Cochrane Collaboration, and use "meta-analysis" to refer to statistical methods of combining evidence, leaving other aspects of 'research synthesis' or 'evidence synthesis', such as combining information from qualitative studies, for the more general context of systematic reviews. A meta-analysis is a secondary source.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  keywords = {done}
}

@article{wikipediaMetaAnalysis2020a,
  title = {Meta-{{Analysis}}},
  author = {{wikipedia}},
  date = {2020-08},
  journaltitle = {Wikipedia},
  abstract = {A meta-analysis is a statistical analysis that combines the results of multiple scientific studies. Meta-analysis can be performed when there are multiple scientific studies addressing the same question, with each individual study reporting measurements that are expected to have some degree of error. The aim then is to use approaches from statistics to derive a pooled estimate closest to the unknown common truth based on how this error is perceived. Existing methods for meta-analysis yield a weighted average from the results of the individual studies, and what differs is the manner in which these weights are allocated and also the manner in which the uncertainty is computed around the point estimate thus generated. In addition to providing an estimate of the unknown common truth, meta-analysis has the capacity to contrast results from different studies and identify patterns among study results, sources of disagreement among those results, or other interesting relationships that may come to light in the context of multiple studies.A key benefit of this approach is the aggregation of information leading to a higher statistical power and more robust point estimate than is possible from the measure derived from any individual study. However, in performing a meta-analysis, an investigator must make choices which can affect the results, including deciding how to search for studies, selecting studies based on a set of objective criteria, dealing with incomplete data, analyzing the data, and accounting for or choosing not to account for publication bias. Judgment calls made in completing a meta-analysis may affect the results. For example, Wanous and colleagues examined four pairs of meta-analyses on the four topics of (a) job performance and satisfaction relationship, (b) realistic job previews, (c) correlates of role conflict and ambiguity, and (d) the job satisfaction and absenteeism relationship, and illustrated how various judgement calls made by the researchers produced different results.Meta-analyses are often, but not always, important components of a systematic review procedure. For instance, a meta-analysis may be conducted on several clinical trials of a medical treatment, in an effort to obtain a better understanding of how well the treatment works. Here it is convenient to follow the terminology used by the Cochrane Collaboration, and use "meta-analysis" to refer to statistical methods of combining evidence, leaving other aspects of 'research synthesis' or 'evidence synthesis', such as combining information from qualitative studies, for the more general context of systematic reviews. A meta-analysis is a secondary source.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  keywords = {done}
}

@article{wilhelmsson2000,
  title = {The Impact of Traffic Noise on the Values of Single-Family Houses},
  author = {Wilhelmsson, M},
  date = {2000},
  journaltitle = {Journal of Environmental Planning and Management},
  volume = {43},
  number = {6},
  pages = {799--815},
  date-modified = {2012-02-28 12:24:08 +0000}
}

@book{wilke,
  title = {Fundamentals of {{Data Visualization}}},
  author = {Wilke, Claus O.},
  url = {https://clauswilke.com/dataviz/},
  urldate = {2021-05-12},
  abstract = {A guide to making visualizations that accurately reflect the data, tell a story, and look professional.},
  file = {/Users/agwd/Zotero/storage/3D45LD3Y/dataviz.html}
}

@incollection{wood2006,
  title = {Generalized Additive Models},
  booktitle = {An Introduction with {{R}}},
  author = {Wood, SN},
  date = {2006},
  publisher = {{Texts in Statistical Science}},
  location = {{Chapman \& Hall/CRC, New YorkTexts in Statistical Science, Chapman \& Hall/CRC, New York}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{wooldridge2003,
  title = {Introductory Econometrics. {{A}} Modern Approach.},
  author = {Wooldridge, JM},
  date = {2003},
  publisher = {{Thomson. South Western}},
  location = {{USA}},
  date-modified = {2012-02-28 12:24:08 +0000},
  keywords = {ocp022019_REGION_template}
}

@article{xiao2016,
  title = {Urban Configuration, Accessibility, and Property Prices: A Case Study of {{Cardiff}}, {{Wales}}},
  author = {Xiao, Y and Orford, S and Webster, C J},
  date = {2016},
  journaltitle = {Environment and Planning B: Planning and Design},
  volume = {43},
  pages = {108--129},
  date-added = {2015-10-20 11:35:51 +0000},
  date-modified = {2015-10-20 11:36:52 +0000},
  keywords = {ocp022019_REGION_template}
}

@book{xie,
  title = {R {{Markdown Cookbook}}},
  author = {Xie, Yihui and Dervieux, Christophe and Riederer, Emily},
  url = {https://bookdown.org/yihui/rmarkdown-cookbook/},
  urldate = {2020-09-25},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  file = {/Users/agwd/Zotero/storage/R57E5JD3/rmarkdown-cookbook.html}
}

@incollection{xie2014,
  title = {Knitr: {{A}} Comprehensive Tool for Reproducible Research in {{R}}},
  booktitle = {Implementing Reproducible Computational Research},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  url = {http://www.crcpress.com/product/isbn/9781466561595}
}

@incollection{xie2014a,
  title = {Knitr: {{A}} Comprehensive Tool for Reproducible Research in {{R}}},
  booktitle = {Implementing Reproducible Computational Research},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  url = {http://www.crcpress.com/product/isbn/9781466561595}
}

@incollection{xie2014b,
  title = {Knitr: {{A Comprehensive Tool}} for {{Reproducible Research}} in {{R}}},
  booktitle = {Implementing {{Reproducible Computational Research}}},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  keywords = {done}
}

@incollection{xie2014c,
  title = {Knitr: {{A Comprehensive Tool}} for {{Reproducible Research}} in {{R}}},
  booktitle = {Implementing {{Reproducible Computational Research}}},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  keywords = {done}
}

@book{xie2015,
  title = {Dynamic Documents with {{R}} and Knitr},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  url = {https://yihui.org/knitr/}
}

@book{xie2015a,
  title = {Dynamic Documents with {{R}} and Knitr},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  url = {https://yihui.org/knitr/}
}

@book{xie2015b,
  title = {Dynamic {{Documents}} with {{R}} and {{Knitr}}},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@book{xie2015c,
  title = {Dynamic {{Documents}} with {{R}} and {{Knitr}}},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@book{xie2018,
  title = {R Markdown: {{The}} Definitive Guide},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  url = {https://bookdown.org/yihui/rmarkdown}
}

@book{xie2018a,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@book{xie2018b,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@manual{xie2020,
  type = {manual},
  title = {Knitr: {{A}} General-Purpose Package for Dynamic Report Generation in r},
  author = {Xie, Yihui},
  date = {2020},
  url = {https://yihui.org/knitr/}
}

@book{xie2020a,
  title = {Knitr: {{A}} General-Purpose Package for Dynamic Report Generation in r},
  author = {Xie, Yihui},
  date = {2020},
  url = {https://yihui.org/knitr/}
}

@book{xie2020b,
  type = {Manual},
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in r},
  author = {Xie, Yihui},
  date = {2020},
  keywords = {done}
}

@book{xie2020c,
  type = {Manual},
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in r},
  author = {Xie, Yihui},
  date = {2020},
  keywords = {done}
}

@book{xieDynamicDocumentsKnitr2015,
  title = {Dynamic {{Documents}} with {{R}} and {{Knitr}}},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@book{xieDynamicDocumentsKnitr2015a,
  title = {Dynamic {{Documents}} with {{R}} and {{Knitr}}},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@incollection{xieKnitrComprehensiveTool2014,
  title = {Knitr: {{A Comprehensive Tool}} for {{Reproducible Research}} in {{R}}},
  booktitle = {Implementing {{Reproducible Computational Research}}},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  keywords = {done}
}

@incollection{xieKnitrComprehensiveTool2014a,
  title = {Knitr: {{A Comprehensive Tool}} for {{Reproducible Research}} in {{R}}},
  booktitle = {Implementing {{Reproducible Computational Research}}},
  author = {Xie, Yihui},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{Chapman and Hall/CRC}},
  keywords = {done}
}

@book{xieKnitrGeneralPurposePackage2020,
  type = {Manual},
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in r},
  author = {Xie, Yihui},
  date = {2020},
  keywords = {done}
}

@book{xieKnitrGeneralPurposePackage2020a,
  type = {Manual},
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in r},
  author = {Xie, Yihui},
  date = {2020},
  keywords = {done}
}

@book{xieMarkdownDefinitiveGuide2018,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@book{xieMarkdownDefinitiveGuide2018a,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  keywords = {done}
}

@manual{yoshida2020,
  type = {manual},
  title = {Tableone: {{Create}} 'table 1' to Describe Baseline Characteristics with or without Propensity Score Weights},
  author = {Yoshida, Kazuki and Bartel, Alexander},
  date = {2020},
  url = {https://CRAN.R-project.org/package=tableone}
}

@article{young2008,
  title = {Why {{Current Publication Practices May Distort Science}}},
  author = {Young, Neal S and Ioannidis, John P. A and Al-Ubaydli, Omar},
  date = {2008-10-07},
  journaltitle = {PLoS Medicine},
  shortjournal = {PLoS Med},
  volume = {5},
  number = {10},
  pages = {e201},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050201},
  url = {https://dx.plos.org/10.1371/journal.pmed.0050201},
  urldate = {2020-09-10},
  abstract = {The current system of publication in biomedical research provides a distorted view of the reality of scientific data that are generated in the laboratory and clinic. This system can be studied by applying principles from the field of economics. The “winner’s curse,” a more general statement of publication bias, suggests that the small proportion of results chosen for publication are unrepresentative of scientists’ repeated samplings of the real world. The self-correcting mechanism in science is retarded by the extreme imbalance between the abundance of supply (the output of basic science laboratories and clinical investigations) and the increasingly limited venues for publication (journals with sufficiently high impact). This system would be expected intrinsically to lead to the misallocation of resources. The scarcity of available outlets is artificial, based on the costs of printing in an electronic age and a belief that selectivity is equivalent to quality. Science is subject to great uncertainty: we cannot be confident now which efforts will ultimately yield worthwhile achievements. However, the current system abdicates to a small number of intermediates an authoritative prescience to anticipate a highly unpredictable future. In considering society’s expectations and our own goals as scientists, we believe that there is a moral imperative to reconsider how scientific data are judged and disseminated.},
  langid = {english},
  file = {/Users/agwd/Zotero/storage/GN54LYE7/Young et al. - 2008 - Why Current Publication Practices May Distort Scie.pdf}
}

@article{young2008a,
  title = {Why {{Current Publication Practices May Distort Science}}},
  author = {Young, Neal S and Ioannidis, John P. A and Al-Ubaydli, Omar},
  date = {2008-10},
  journaltitle = {PLoS Medicine},
  volume = {5},
  number = {10},
  pages = {e201},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050201},
  abstract = {The current system of publication in biomedical research provides a distorted view of the reality of scientific data that are generated in the laboratory and clinic. This system can be studied by applying principles from the field of economics. The “winner's curse,” a more general statement of publication bias, suggests that the small proportion of results chosen for publication are unrepresentative of scientists' repeated samplings of the real world. The self-correcting mechanism in science is retarded by the extreme imbalance between the abundance of supply (the output of basic science laboratories and clinical investigations) and the increasingly limited venues for publication (journals with sufficiently high impact). This system would be expected intrinsically to lead to the misallocation of resources. The scarcity of available outlets is artificial, based on the costs of printing in an electronic age and a belief that selectivity is equivalent to quality. Science is subject to great uncertainty: we cannot be confident now which efforts will ultimately yield worthwhile achievements. However, the current system abdicates to a small number of intermediates an authoritative prescience to anticipate a highly unpredictable future. In considering society's expectations and our own goals as scientists, we believe that there is a moral imperative to reconsider how scientific data are judged and disseminated.},
  langid = {english},
  keywords = {done}
}

@article{young2008b,
  title = {Why {{Current Publication Practices May Distort Science}}},
  author = {Young, Neal S and Ioannidis, John P. A and Al-Ubaydli, Omar},
  date = {2008-10},
  journaltitle = {PLoS Medicine},
  volume = {5},
  number = {10},
  pages = {e201},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050201},
  abstract = {The current system of publication in biomedical research provides a distorted view of the reality of scientific data that are generated in the laboratory and clinic. This system can be studied by applying principles from the field of economics. The “winner's curse,” a more general statement of publication bias, suggests that the small proportion of results chosen for publication are unrepresentative of scientists' repeated samplings of the real world. The self-correcting mechanism in science is retarded by the extreme imbalance between the abundance of supply (the output of basic science laboratories and clinical investigations) and the increasingly limited venues for publication (journals with sufficiently high impact). This system would be expected intrinsically to lead to the misallocation of resources. The scarcity of available outlets is artificial, based on the costs of printing in an electronic age and a belief that selectivity is equivalent to quality. Science is subject to great uncertainty: we cannot be confident now which efforts will ultimately yield worthwhile achievements. However, the current system abdicates to a small number of intermediates an authoritative prescience to anticipate a highly unpredictable future. In considering society's expectations and our own goals as scientists, we believe that there is a moral imperative to reconsider how scientific data are judged and disseminated.},
  langid = {english},
  keywords = {done}
}

@article{youngWhyCurrentPublication2008,
  title = {Why {{Current Publication Practices May Distort Science}}},
  author = {Young, Neal S and Ioannidis, John P. A and Al-Ubaydli, Omar},
  date = {2008-10},
  journaltitle = {PLoS Medicine},
  volume = {5},
  number = {10},
  pages = {e201},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050201},
  abstract = {The current system of publication in biomedical research provides a distorted view of the reality of scientific data that are generated in the laboratory and clinic. This system can be studied by applying principles from the field of economics. The “winner's curse,” a more general statement of publication bias, suggests that the small proportion of results chosen for publication are unrepresentative of scientists' repeated samplings of the real world. The self-correcting mechanism in science is retarded by the extreme imbalance between the abundance of supply (the output of basic science laboratories and clinical investigations) and the increasingly limited venues for publication (journals with sufficiently high impact). This system would be expected intrinsically to lead to the misallocation of resources. The scarcity of available outlets is artificial, based on the costs of printing in an electronic age and a belief that selectivity is equivalent to quality. Science is subject to great uncertainty: we cannot be confident now which efforts will ultimately yield worthwhile achievements. However, the current system abdicates to a small number of intermediates an authoritative prescience to anticipate a highly unpredictable future. In considering society's expectations and our own goals as scientists, we believe that there is a moral imperative to reconsider how scientific data are judged and disseminated.},
  langid = {english},
  keywords = {done}
}

@article{youngWhyCurrentPublication2008a,
  title = {Why {{Current Publication Practices May Distort Science}}},
  author = {Young, Neal S and Ioannidis, John P. A and Al-Ubaydli, Omar},
  date = {2008-10},
  journaltitle = {PLoS Medicine},
  volume = {5},
  number = {10},
  pages = {e201},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050201},
  abstract = {The current system of publication in biomedical research provides a distorted view of the reality of scientific data that are generated in the laboratory and clinic. This system can be studied by applying principles from the field of economics. The “winner's curse,” a more general statement of publication bias, suggests that the small proportion of results chosen for publication are unrepresentative of scientists' repeated samplings of the real world. The self-correcting mechanism in science is retarded by the extreme imbalance between the abundance of supply (the output of basic science laboratories and clinical investigations) and the increasingly limited venues for publication (journals with sufficiently high impact). This system would be expected intrinsically to lead to the misallocation of resources. The scarcity of available outlets is artificial, based on the costs of printing in an electronic age and a belief that selectivity is equivalent to quality. Science is subject to great uncertainty: we cannot be confident now which efforts will ultimately yield worthwhile achievements. However, the current system abdicates to a small number of intermediates an authoritative prescience to anticipate a highly unpredictable future. In considering society's expectations and our own goals as scientists, we believe that there is a moral imperative to reconsider how scientific data are judged and disseminated.},
  langid = {english},
  keywords = {done}
}

@online{zotero-172,
  title = {Hva er nytt i Firefox},
  url = {https://www.mozilla.org/nb-NO/firefox/80.0/whatsnew/all/},
  urldate = {2020-08-28},
  abstract = {Hva er nytt i Firefox},
  langid = {norsk},
  organization = {{Mozilla}},
  file = {/Users/agwd/Zotero/storage/8IJVJW8X/all.html}
}

@online{zotero-205,
  title = {Norske Børshandlede Fond : En Kvantitativ Analyse Av Fondenes Egenskaper - {{CORE}}},
  url = {https://core.ac.uk/display/52072194},
  urldate = {2020-05-07},
  file = {/Users/agwd/Zotero/storage/X5T3CRB2/52072194.html}
}

@online{zotero-212,
  url = {https://bibsys-almaprimo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=BIBSYS_ILS71542116430002201&context=L&vid=HIB&lang=nn_NO&search_scope=all_blended&adaptor=Local%20Search%20Engine&isFrbr=true&tab=default_tab&query=any,contains,r%20for%20data%20science&sortby=date&facet=frbrgroupid,include,257567799&offset=0},
  urldate = {2020-03-27}
}

@online{zotero-213,
  title = {Pandoc - {{Pandoc User}}’s {{Guide}}},
  url = {https://pandoc.org/MANUAL.html},
  urldate = {2020-03-10},
  file = {/Users/agwd/Zotero/storage/BKLFW3LT/MANUAL.html}
}

@online{zotero-228,
  title = {Opinion | {{I}} like {{Elizabeth Warren}}. {{Too}} Bad She’s a Hypocrite.},
  url = {https://www.washingtonpost.com/opinions/i-like-elizabeth-warren-too-bad-shes-a-hypocrite/2019/09/11/409d5ed0-d4d3-11e9-86ac-0f250cc91758_story.html},
  urldate = {2019-09-12},
  abstract = {Her campaign finance promises are hypocritical.},
  langid = {english},
  organization = {{Washington Post}},
  file = {/Users/agwd/Zotero/storage/N94GZ9GG/409d5ed0-d4d3-11e9-86ac-0f250cc91758_story.html}
}

@online{zotero-229,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  url = {https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/p/book/9781482253443},
  urldate = {2019-04-30},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers’ knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today’s model-based statistics, the book pushes readers to perform step-by-step calculations that are usual},
  langid = {english},
  organization = {{CRC Press}},
  file = {/Users/agwd/Zotero/storage/G7W5DZQY/9781482253443.html}
}

@online{zotero-238,
  title = {Spgwr.Pdf},
  url = {https://docs.google.com/viewer?url=https%3A%2F%2Fcran.microsoft.com%2Fweb%2Fpackages%2Fspgwr%2Fspgwr.pdf&pdf=true},
  urldate = {2019-04-10},
  file = {/Users/agwd/Zotero/storage/9KMZ67CZ/viewer.html}
}

@online{zotero-239,
  title = {{{spData}} Package | {{R Documentation}}},
  url = {https://www.rdocumentation.org/packages/spData/versions/0.3.0},
  urldate = {2019-04-10},
  file = {/Users/agwd/Zotero/storage/Q6ASPL3B/0.3.html}
}

@online{zotero-242,
  title = {Online {{Data}} - {{Robert Shiller}}},
  url = {http://www.econ.yale.edu/~shiller/data.htm},
  urldate = {2018-09-20},
  file = {/Users/agwd/Zotero/storage/SMYXLD9X/data.html}
}

@online{zotero-245,
  title = {Options {{Symbology Initiative}} ({{OSI}})},
  url = {http://optionsymbologyinitiative.blogspot.com/},
  urldate = {2018-01-18},
  file = {/Users/agwd/Zotero/storage/CFWPF55S/optionsymbologyinitiative.blogspot.no.html}
}

@online{zotero-249,
  title = {Quick\_start\_guide [{{Zotero Documentation}}]},
  url = {https://www.zotero.org/support/quick_start_guide},
  urldate = {2018-01-16},
  file = {/Users/agwd/Zotero/storage/KAN6TZZ3/quick_start_guide.html}
}

@online{zotero-25,
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jors.12188},
  urldate = {2021-06-22},
  file = {/Users/agwd/Zotero/storage/GDS97BI5/jors.html}
}

@online{zotero-26,
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jors.12188}
}

@online{zotero-296,
  title = {American {{Economic Association}}},
  url = {https://www.aeaweb.org/journals/data},
  urldate = {2020-09-11},
  file = {/Users/agwd/Zotero/storage/MK7T7YML/data.html}
}

@online{zotero-30,
  title = {One-Step Estimation of Spatial Dependence Parameters: {{Properties}} and Extensions of the {{APLE}} Statistic | {{Elsevier Enhanced Reader}}},
  shorttitle = {One-Step Estimation of Spatial Dependence Parameters},
  doi = {10.1016/j.jmva.2011.08.006},
  url = {https://reader.elsevier.com/reader/sd/pii/S0047259X11001655?token=596A441C343F3E9108CC35E1B1FBC4650A26CC3C65AC7F3D940E283452EE8232235F1C0F2D3D5337BDFCBF9BD370A1C1&originRegion=eu-west-1&originCreation=20210625063325},
  urldate = {2021-06-25},
  langid = {english}
}

@online{zotero-311,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} (Nsf16137) | {{NSF}} - {{National Science Foundation}}},
  url = {https://www.nsf.gov/pubs/2016/nsf16137/nsf16137.jsp},
  urldate = {2020-09-10},
  file = {/Users/agwd/Zotero/storage/CARGSTUK/nsf16137.html}
}

@online{zotero-322,
  title = {Introduction to Tableone},
  url = {https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html},
  urldate = {2020-09-02},
  file = {/Users/agwd/Zotero/storage/HWZA3CLC/introduction.html}
}

@online{zotero-351,
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jors.12188},
  urldate = {2021-06-22}
}

@online{zotero-354,
  title = {Forslag Til Utvekslingsformat for Digitale Geodata ({{SOSI}}-Formatet, Versjon 1.0) - {{Nasjonalbiblioteket}}},
  url = {https://www.nb.no/nbsok/nb/62d23fb9bb9c18f9c57f88f8945e30ef.nbdigital?lang=no#5},
  urldate = {2020-12-14},
  file = {/Users/agwd/Zotero/storage/HXH2CKAD/62d23fb9bb9c18f9c57f88f8945e30ef.html}
}

@online{zotero-355,
  title = {Forslag Til Utvekslingsformat for Digitale Geodata ({{SOSI}}-Formatet, Versjon 1.0) - {{Nasjonalbiblioteket}}},
  url = {https://www.nb.no/nbsok/nb/62d23fb9bb9c18f9c57f88f8945e30ef.nbdigital?lang=no#5},
  urldate = {2020-12-14},
  file = {/Users/agwd/Zotero/storage/KLD4IVC2/62d23fb9bb9c18f9c57f88f8945e30ef.html}
}

@online{zotero-356,
  title = {Tidying the {{Australian Same Sex Marriage Postal Survey Data}} with {{R}} | by {{Miles McBain}} | {{Medium}}},
  url = {https://medium.com/@miles.mcbain/tidying-the-australian-same-sex-marriage-postal-survey-data-with-r-5d35cea07962},
  urldate = {2020-12-04},
  file = {/Users/agwd/Zotero/storage/LQJBMJL2/tidying-the-australian-same-sex-marriage-postal-survey-data-with-r-5d35cea07962.html}
}

@book{zotero-366,
  title = {Pandoc - {{Pandoc User}}'s {{Guide}}}
}

@book{zotero-367,
  title = {Pandoc - {{Pandoc User}}'s {{Guide}}}
}

@book{zotero-368,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{zotero-369,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{zotero-370,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{zotero-371,
  title = {Dear {{Colleague Letter}}: {{Robust}} and {{Reliable Research}} in the {{Social}}, {{Behavioral}}, and {{Economic Sciences}} ({{Nsf16137}}) | {{NSF}} - {{National Science Foundation}}},
  keywords = {done}
}

@book{zotero-381,
  title = {American {{Economic Association}}}
}

@book{zotero-384,
  title = {American {{Economic Association}}}
}


